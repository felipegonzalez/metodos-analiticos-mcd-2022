<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Modelos de lenguaje y n-gramas | Métodos analíticos, ITAM 2022</title>
  <meta name="description" content="Notas para métodos analíticos 2022" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Modelos de lenguaje y n-gramas | Métodos analíticos, ITAM 2022" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Notas para métodos analíticos 2022" />
  <meta name="github-repo" content="felipexgonzalez/metodos-analiticos-mcd-2022" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Modelos de lenguaje y n-gramas | Métodos analíticos, ITAM 2022" />
  
  <meta name="twitter:description" content="Notas para métodos analíticos 2022" />
  

<meta name="author" content="Felipe González" />


<meta name="date" content="2022-05-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="detección-de-comunidades.html"/>
<link rel="next" href="representación-de-palabras-y-word2vec.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.20/datatables.js"></script>
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.11.3/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.11.3/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<link href="libs/vis-9.1.0/vis-network.min.css" rel="stylesheet" />
<script src="libs/vis-9.1.0/vis-network.min.js"></script>
<script src="libs/visNetwork-binding-2.1.0/visNetwork.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Métodos Analíticos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Temario</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#evaluación"><i class="fa fa-check"></i>Evaluación</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#simlitud-en-dimensión-alta"><i class="fa fa-check"></i>Simlitud en dimensión alta</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#medidas-de-distancia-o-similitud"><i class="fa fa-check"></i>Medidas de distancia o similitud</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#tipos-de-soluciones"><i class="fa fa-check"></i>Tipos de soluciones</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#proyección-y-búsqueda-de-marginales-interesantes"><i class="fa fa-check"></i>Proyección y búsqueda de marginales interesantes</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#proyecciones-globales"><i class="fa fa-check"></i>Proyecciones globales</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#descripción-de-estructura-local"><i class="fa fa-check"></i>Descripción de estructura local</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#inmersiones-embeddings"><i class="fa fa-check"></i>Inmersiones (embeddings)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="frecuentes.html"><a href="frecuentes.html"><i class="fa fa-check"></i><b>2</b> Análisis de conjuntos frecuentes</a>
<ul>
<li class="chapter" data-level="2.1" data-path="frecuentes.html"><a href="frecuentes.html#datos-de-canastas"><i class="fa fa-check"></i><b>2.1</b> Datos de canastas</a></li>
<li class="chapter" data-level="2.2" data-path="frecuentes.html"><a href="frecuentes.html#conjuntos-frecuentes"><i class="fa fa-check"></i><b>2.2</b> Conjuntos frecuentes</a></li>
<li class="chapter" data-level="2.3" data-path="frecuentes.html"><a href="frecuentes.html#monotonicidad-de-conjuntos-frecuentes"><i class="fa fa-check"></i><b>2.3</b> Monotonicidad de conjuntos frecuentes</a></li>
<li class="chapter" data-level="2.4" data-path="frecuentes.html"><a href="frecuentes.html#algoritmo-a-priori"><i class="fa fa-check"></i><b>2.4</b> Algoritmo a-priori</a></li>
<li class="chapter" data-level="2.5" data-path="frecuentes.html"><a href="frecuentes.html#modelos-simples-para-análisis-de-canastas"><i class="fa fa-check"></i><b>2.5</b> Modelos simples para análisis de canastas</a>
<ul>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-3"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#modelo-de-artículos-independientes"><i class="fa fa-check"></i>Modelo de artículos independientes</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="frecuentes.html"><a href="frecuentes.html#soporte-teórico-y-conjuntos-frecuentes"><i class="fa fa-check"></i><b>2.6</b> Soporte teórico y conjuntos frecuentes</a>
<ul>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-4"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="frecuentes.html"><a href="frecuentes.html#reglas-de-asociación"><i class="fa fa-check"></i><b>2.7</b> Reglas de asociación</a>
<ul>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-5"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-6"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="frecuentes.html"><a href="frecuentes.html#dificultades-en-el-análisis-de-canastas"><i class="fa fa-check"></i><b>2.8</b> Dificultades en el análisis de canastas</a></li>
<li class="chapter" data-level="2.9" data-path="frecuentes.html"><a href="frecuentes.html#otras-medidas-de-calidad-de-reglas"><i class="fa fa-check"></i><b>2.9</b> Otras medidas de calidad de reglas</a>
<ul>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#hyper-lift-bajo-hipótesis-de-independencia"><i class="fa fa-check"></i>Hyper-lift bajo hipótesis de independencia</a></li>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#hyper-lift-para-datos-de-canastas"><i class="fa fa-check"></i>Hyper-lift para datos de canastas</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="frecuentes.html"><a href="frecuentes.html#selección-de-reglas"><i class="fa fa-check"></i><b>2.10</b> Selección de reglas</a>
<ul>
<li class="chapter" data-level="" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-canastas-grandes"><i class="fa fa-check"></i>Ejemplo: canastas grandes</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="frecuentes.html"><a href="frecuentes.html#búsqueda-de-reglas-especializadas"><i class="fa fa-check"></i><b>2.11</b> Búsqueda de reglas especializadas</a></li>
<li class="chapter" data-level="2.12" data-path="frecuentes.html"><a href="frecuentes.html#visualización-de-asociaciones"><i class="fa fa-check"></i><b>2.12</b> Visualización de asociaciones</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo-canastas"><i class="fa fa-check"></i><b>2.12.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="frecuentes.html"><a href="frecuentes.html#otras-aplicaciones"><i class="fa fa-check"></i><b>2.13</b> Otras aplicaciones</a></li>
<li class="chapter" data-level="2.14" data-path="frecuentes.html"><a href="frecuentes.html#ejercicios"><i class="fa fa-check"></i><b>2.14</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="similitud.html"><a href="similitud.html"><i class="fa fa-check"></i><b>3</b> Similitud y vecinos cercanos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="similitud.html"><a href="similitud.html#similitud-de-conjuntos"><i class="fa fa-check"></i><b>3.1</b> Similitud de conjuntos</a></li>
<li class="chapter" data-level="3.2" data-path="similitud.html"><a href="similitud.html#representación-de-documentos-como-conjuntos"><i class="fa fa-check"></i><b>3.2</b> Representación de documentos como conjuntos</a></li>
<li class="chapter" data-level="3.3" data-path="similitud.html"><a href="similitud.html#representación-matricial"><i class="fa fa-check"></i><b>3.3</b> Representación matricial</a></li>
<li class="chapter" data-level="3.4" data-path="similitud.html"><a href="similitud.html#minhash-y-reducción-probabilística-de-dimensionalidad"><i class="fa fa-check"></i><b>3.4</b> Minhash y reducción probabilística de dimensionalidad</a></li>
<li class="chapter" data-level="3.5" data-path="similitud.html"><a href="similitud.html#agrupando-textos-de-similitud-alta"><i class="fa fa-check"></i><b>3.5</b> Agrupando textos de similitud alta</a></li>
<li class="chapter" data-level="3.6" data-path="similitud.html"><a href="similitud.html#ejemplo-tweets"><i class="fa fa-check"></i><b>3.6</b> Ejemplo: tweets</a></li>
<li class="chapter" data-level="3.7" data-path="similitud.html"><a href="similitud.html#verificar-si-un-nuevo-elemento-es-duplicado"><i class="fa fa-check"></i><b>3.7</b> Verificar si un nuevo elemento es duplicado</a></li>
<li class="chapter" data-level="3.8" data-path="similitud.html"><a href="similitud.html#controlando-la-sensibilidad-y-umbral-de-similitud"><i class="fa fa-check"></i><b>3.8</b> Controlando la sensibilidad y umbral de similitud</a></li>
<li class="chapter" data-level="3.9" data-path="similitud.html"><a href="similitud.html#distancia-euclideana-y-lsh"><i class="fa fa-check"></i><b>3.9</b> Distancia euclideana y LSH</a></li>
<li class="chapter" data-level="3.10" data-path="similitud.html"><a href="similitud.html#locality-sensitive-hashing-lsh"><i class="fa fa-check"></i><b>3.10</b> Locality Sensitive Hashing (LSH)</a></li>
<li class="chapter" data-level="3.11" data-path="similitud.html"><a href="similitud.html#lsh-para-imágenes"><i class="fa fa-check"></i><b>3.11</b> LSH para imágenes</a></li>
<li class="chapter" data-level="3.12" data-path="similitud.html"><a href="similitud.html#joins-por-similitud"><i class="fa fa-check"></i><b>3.12</b> Joins por similitud</a></li>
<li class="chapter" data-level="3.13" data-path="similitud.html"><a href="similitud.html#ejemplo-entity-matching"><i class="fa fa-check"></i><b>3.13</b> Ejemplo: entity matching</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html"><i class="fa fa-check"></i><b>4</b> DVS y reducción de dimensionalidad</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#descomposición-aditiva-en-matrices-de-rango-1"><i class="fa fa-check"></i><b>4.1</b> Descomposición aditiva en matrices de rango 1</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#matrices-de-rango-1"><i class="fa fa-check"></i><b>4.1.1</b> Matrices de rango 1</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-una-matriz-de-rango-1-de-preferencias"><i class="fa fa-check"></i>Ejemplo: una matriz de rango 1 de preferencias</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#aproximación-con-matrices-de-rango-1."><i class="fa fa-check"></i><b>4.2</b> Aproximación con matrices de rango 1.</a>
<ul>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-12"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="4.2.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#suma-de-matrices-de-rango-1."><i class="fa fa-check"></i><b>4.2.1</b> Suma de matrices de rango 1.</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-películas"><i class="fa fa-check"></i>Ejemplo: películas</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#aproximación-con-matrices-de-rango-bajo"><i class="fa fa-check"></i><b>4.3</b> Aproximación con matrices de rango bajo</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#discusión-aproximación-de-rango-1."><i class="fa fa-check"></i><b>4.3.1</b> Discusión: aproximación de rango 1.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#interpetación-de-vectores-singulares"><i class="fa fa-check"></i><b>4.4</b> Interpetación de vectores singulares</a>
<ul>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-14"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="4.4.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#discusión-aproximaciones-de-rango-más-alto"><i class="fa fa-check"></i><b>4.4.1</b> Discusión: aproximaciones de rango más alto</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-15"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#descomposición-en-valores-singulares-svd-o-dvs"><i class="fa fa-check"></i><b>4.5</b> Descomposición en valores singulares (SVD o DVS)</a></li>
<li class="chapter" data-level="4.6" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#más-de-interpretación-geométrica"><i class="fa fa-check"></i><b>4.6</b> Más de interpretación geométrica</a></li>
<li class="chapter" data-level="4.7" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#svd-para-películas-de-netflix"><i class="fa fa-check"></i><b>4.7</b> SVD para películas de netflix</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#calidad-de-representación-de-svd."><i class="fa fa-check"></i><b>4.7.1</b> Calidad de representación de SVD.</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-16"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#componentes-principales"><i class="fa fa-check"></i><b>4.8</b> Componentes principales</a>
<ul>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#varianza-en-componentes-principales"><i class="fa fa-check"></i>Varianza en componentes principales</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#centrar-o-no-centrar-por-columna"><i class="fa fa-check"></i>¿Centrar o no centrar por columna?</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-resultados-similares"><i class="fa fa-check"></i>Ejemplo: resultados similares</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplos-donde-es-buena-idea-centrar"><i class="fa fa-check"></i>Ejemplos: donde es buena idea centrar</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#ejemplo-donde-no-centrar-funciona-bien"><i class="fa fa-check"></i>Ejemplo: donde no centrar funciona bien</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#otros-tipos-de-centrado"><i class="fa fa-check"></i>Otros tipos de centrado</a></li>
<li class="chapter" data-level="" data-path="dvs-y-reducción-de-dimensionalidad.html"><a href="dvs-y-reducción-de-dimensionalidad.html#reescalando-variables"><i class="fa fa-check"></i>Reescalando variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html"><i class="fa fa-check"></i><b>5</b> Sistemas de recomendación y filtrado colaborativo</a>
<ul>
<li class="chapter" data-level="5.1" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#enfoques-de-recomendación"><i class="fa fa-check"></i><b>5.1</b> Enfoques de recomendación</a></li>
<li class="chapter" data-level="5.2" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#datos"><i class="fa fa-check"></i><b>5.2</b> Datos</a>
<ul>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejemplo-18"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#modelos-de-referencia-y-evaluación"><i class="fa fa-check"></i><b>5.3</b> Modelos de referencia y evaluación</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#evaluación-de-predicciones"><i class="fa fa-check"></i><b>5.3.1</b> Evaluación de predicciones</a></li>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejemplo-datos-de-netflix"><i class="fa fa-check"></i>Ejemplo: datos de Netflix</a></li>
<li class="chapter" data-level="5.3.2" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#opcional-efectos-en-análisis-de-heterogeneidad-en-uso-de-escala"><i class="fa fa-check"></i><b>5.3.2</b> (Opcional) Efectos en análisis de heterogeneidad en uso de escala</a></li>
<li class="chapter" data-level="5.3.3" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo"><i class="fa fa-check"></i><b>5.3.3</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#modelo-de-referencia"><i class="fa fa-check"></i><b>5.4</b> Modelo de referencia</a>
<ul>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejercicio-modelo-de-referencia-para-netflix"><i class="fa fa-check"></i>Ejercicio: modelo de referencia para Netflix</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#filtrado-colaborativo-similitud"><i class="fa fa-check"></i><b>5.5</b> Filtrado colaborativo: similitud</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#simitems"><i class="fa fa-check"></i><b>5.5.1</b> Cálculo de similitud entre usuarios/películas</a></li>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejemplo-19"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejemplo-cómo-se-ven-las-calificaciones-de-películas-similaresno-similares"><i class="fa fa-check"></i>Ejemplo: ¿cómo se ven las calificaciones de películas similares/no similares?</a></li>
<li class="chapter" data-level="" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#ejercicio-4"><i class="fa fa-check"></i>Ejercicio</a></li>
<li class="chapter" data-level="5.5.2" data-path="sistemas-de-recomendación-y-filtrado-colaborativo.html"><a href="sistemas-de-recomendación-y-filtrado-colaborativo.html#implementación"><i class="fa fa-check"></i><b>5.5.2</b> Implementación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html"><i class="fa fa-check"></i><b>6</b> Dimensiones latentes para recomendación</a>
<ul>
<li class="chapter" data-level="6.0.1" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo"><i class="fa fa-check"></i><b>6.0.1</b> Ejemplo: una dimensión latente</a></li>
<li class="chapter" data-level="6.0.2" data-path="frecuentes.html"><a href="frecuentes.html#ejemplo"><i class="fa fa-check"></i><b>6.0.2</b> Ejemplo: dos dimensiones latentes</a></li>
<li class="chapter" data-level="6.0.3" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#combinación-con-modelo-base"><i class="fa fa-check"></i><b>6.0.3</b> Combinación con modelo base</a></li>
<li class="chapter" data-level="6.1" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#factorización-de-matrices"><i class="fa fa-check"></i><b>6.1</b> Factorización de matrices</a></li>
<li class="chapter" data-level="6.2" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#mínimos-cuadrados-alternados"><i class="fa fa-check"></i><b>6.2</b> Mínimos cuadrados alternados</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#mínimos-cuadrados-alternados-con-regularización"><i class="fa fa-check"></i><b>6.2.1</b> Mínimos cuadrados alternados con regularización</a></li>
<li class="chapter" data-level="" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#ejercicio-5"><i class="fa fa-check"></i>Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#retroalimentación-implícita"><i class="fa fa-check"></i><b>6.3</b> Retroalimentación implícita</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#ejemplo-20"><i class="fa fa-check"></i><b>6.3.1</b> Ejemplo</a></li>
<li class="chapter" data-level="6.3.2" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#ejemplo-21"><i class="fa fa-check"></i><b>6.3.2</b> Ejemplo</a></li>
<li class="chapter" data-level="6.3.3" data-path="dimensiones-latentes-para-recomendación.html"><a href="dimensiones-latentes-para-recomendación.html#evaluación-para-modelos-implícitos"><i class="fa fa-check"></i><b>6.3.3</b> Evaluación para modelos implícitos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html"><i class="fa fa-check"></i><b>7</b> Pagerank y análisis de redes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#introducción"><i class="fa fa-check"></i><b>7.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#centralidad-en-redes"><i class="fa fa-check"></i><b>7.1.1</b> Centralidad en redes</a></li>
<li class="chapter" data-level="" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#ejemplo-de-moviegalaxies.com-pulp-fiction"><i class="fa fa-check"></i>Ejemplo de Moviegalaxies.com: Pulp Fiction</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#tipos-de-redes-y-su-representación"><i class="fa fa-check"></i><b>7.2</b> Tipos de redes y su representación</a></li>
<li class="chapter" data-level="7.3" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#visualización-de-redes"><i class="fa fa-check"></i><b>7.3</b> Visualización de redes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#ejercicio-6"><i class="fa fa-check"></i><b>7.3.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#medidas-de-centralidad-para-redes"><i class="fa fa-check"></i><b>7.4</b> Medidas de centralidad para redes</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#grado"><i class="fa fa-check"></i><b>7.4.1</b> Grado</a></li>
<li class="chapter" data-level="7.4.2" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#medida-de-centralidad-betweeness-o-intermediación"><i class="fa fa-check"></i><b>7.4.2</b> Medida de centralidad: <em>Betweeness</em> o <em>Intermediación</em></a></li>
<li class="chapter" data-level="7.4.3" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#medida-de-centralidad-cercanía"><i class="fa fa-check"></i><b>7.4.3</b> Medida de centralidad: Cercanía</a></li>
<li class="chapter" data-level="7.4.4" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#centralidad-de-eigenvector"><i class="fa fa-check"></i><b>7.4.4</b> Centralidad de eigenvector</a></li>
<li class="chapter" data-level="" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#matrices-irreducibles-y-gráficas-fuertemente-conexas"><i class="fa fa-check"></i>Matrices irreducibles y gráficas fuertemente conexas</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#gráficas-dirigidas"><i class="fa fa-check"></i><b>7.5</b> Gráficas dirigidas</a>
<ul>
<li><a href="pagerank-y-análisis-de-redes.html#ejemplos-qué-pasa-si-a-es-no-reducible">Ejemplos: ¿qué pasa si <span class="math inline">\(A\)</span> es no reducible?</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#pagerank"><i class="fa fa-check"></i><b>7.6</b> Pagerank</a>
<ul>
<li class="chapter" data-level="" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#ejemplo-24"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="7.6.1" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#la-matriz-m-es-estocástica"><i class="fa fa-check"></i><b>7.6.1</b> La matriz <span class="math inline">\(M\)</span> es estocástica</a></li>
<li class="chapter" data-level="7.6.2" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#primeras-dificultades"><i class="fa fa-check"></i><b>7.6.2</b> Primeras dificultades</a></li>
<li class="chapter" data-level="7.6.3" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#el-proceso-estocástico-cadena-de-markov-asociado-al-pagerank-versión-simple"><i class="fa fa-check"></i><b>7.6.3</b> El proceso estocástico (cadena de Markov) asociado al Pagerank, versión simple</a></li>
<li class="chapter" data-level="7.6.4" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#matriz-de-transición"><i class="fa fa-check"></i><b>7.6.4</b> Matriz de transición</a></li>
<li class="chapter" data-level="7.6.5" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#distribución-de-equilibrio-versión-simple"><i class="fa fa-check"></i><b>7.6.5</b> Distribución de equilibrio (versión simple)</a></li>
<li class="chapter" data-level="7.6.6" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#distribución-de-equilibrio-y-probabilidades-a-largo-plazo"><i class="fa fa-check"></i><b>7.6.6</b> Distribución de equilibrio y probabilidades a largo plazo</a></li>
<li class="chapter" data-level="7.6.7" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#matriz-de-transición-a-k-pasos"><i class="fa fa-check"></i><b>7.6.7</b> Matriz de transición a <span class="math inline">\(k\)</span> pasos</a></li>
<li class="chapter" data-level="7.6.8" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#pagerank-teletransportaciónperturbación-de-la-matriz-m"><i class="fa fa-check"></i><b>7.6.8</b> Pagerank: teletransportación/perturbación de la matriz <span class="math inline">\(M\)</span></a></li>
<li class="chapter" data-level="7.6.9" data-path="pagerank-y-análisis-de-redes.html"><a href="pagerank-y-análisis-de-redes.html#pagerank-para-buscador"><i class="fa fa-check"></i><b>7.6.9</b> Pagerank para buscador</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="detección-de-comunidades.html"><a href="detección-de-comunidades.html"><i class="fa fa-check"></i><b>8</b> Detección de comunidades</a>
<ul>
<li class="chapter" data-level="8.1" data-path="detección-de-comunidades.html"><a href="detección-de-comunidades.html#modularidad"><i class="fa fa-check"></i><b>8.1</b> Modularidad</a></li>
<li class="chapter" data-level="8.2" data-path="detección-de-comunidades.html"><a href="detección-de-comunidades.html#algoritmo-miope-fast-greedy"><i class="fa fa-check"></i><b>8.2</b> Algoritmo miope (fast greedy)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html"><i class="fa fa-check"></i><b>9</b> Modelos de lenguaje y n-gramas</a>
<ul>
<li class="chapter" data-level="9.1" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#ejemplo-modelo-de-canal-ruidoso"><i class="fa fa-check"></i><b>9.1</b> Ejemplo: Modelo de canal ruidoso</a></li>
<li class="chapter" data-level="9.2" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#corpus-y-vocabulario"><i class="fa fa-check"></i><b>9.2</b> Corpus y vocabulario</a></li>
<li class="chapter" data-level="9.3" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#modelos-de-lenguaje-n-gramas"><i class="fa fa-check"></i><b>9.3</b> Modelos de lenguaje: n-gramas</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#modelo-generativo-de-n-gramas"><i class="fa fa-check"></i><b>9.3.1</b> Modelo generativo de n-gramas</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#modelo-de-n-gramas-usando-conteos"><i class="fa fa-check"></i><b>9.4</b> Modelo de n-gramas usando conteos</a></li>
<li class="chapter" data-level="9.5" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#notas-de-periódico-modelo-de-n-gramas-simples."><i class="fa fa-check"></i><b>9.5</b> Notas de periódico: modelo de n-gramas simples.</a>
<ul>
<li class="chapter" data-level="" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#problema-de-los-ceros"><i class="fa fa-check"></i>Problema de los ceros</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>9.6</b> Evaluación de modelos</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#generación-de-texto"><i class="fa fa-check"></i><b>9.6.1</b> Generación de texto</a></li>
<li class="chapter" data-level="9.6.2" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#evaluación-de-modelos-perplejidad"><i class="fa fa-check"></i><b>9.6.2</b> Evaluación de modelos: perplejidad</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#suavizamiento-de-conteos-otros-métodos"><i class="fa fa-check"></i><b>9.7</b> Suavizamiento de conteos: otros métodos</a>
<ul>
<li class="chapter" data-level="" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#desempeño"><i class="fa fa-check"></i>Desempeño</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="modelos-de-lenguaje-y-n-gramas.html"><a href="modelos-de-lenguaje-y-n-gramas.html#ejemplo-corrector-de-ortografía"><i class="fa fa-check"></i><b>9.8</b> Ejemplo: Corrector de ortografía</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html"><i class="fa fa-check"></i><b>10</b> Representación de palabras y word2vec</a>
<ul>
<li class="chapter" data-level="10.1" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#modelo-de-red-neuronal"><i class="fa fa-check"></i><b>10.1</b> Modelo de red neuronal</a>
<ul>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#ejemplo-32"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#representación-de-palabras"><i class="fa fa-check"></i><b>10.2</b> Representación de palabras</a></li>
<li class="chapter" data-level="10.3" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#modelos-de-word2vec"><i class="fa fa-check"></i><b>10.3</b> Modelos de word2vec</a>
<ul>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#arquitectura-continuous-bag-of-words"><i class="fa fa-check"></i>Arquitectura continuous bag-of-words</a></li>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#arquitectura-skip-grams"><i class="fa fa-check"></i>Arquitectura skip-grams</a></li>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#muestreo-negativo"><i class="fa fa-check"></i>Muestreo negativo</a></li>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#ejemplo-33"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#esprep"><i class="fa fa-check"></i><b>10.4</b> Espacio de representación de palabras</a>
<ul>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#geometría-en-el-espacio-de-representaciones"><i class="fa fa-check"></i>Geometría en el espacio de representaciones</a></li>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#geometría-en-el-espacio-de-representaciones-1"><i class="fa fa-check"></i>Geometría en el espacio de representaciones</a></li>
<li class="chapter" data-level="" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#evaluación-de-calidad-de-modelos"><i class="fa fa-check"></i>Evaluación de calidad de modelos</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="representación-de-palabras-y-word2vec.html"><a href="representación-de-palabras-y-word2vec.html#usos-de-representaciones-distribuidas"><i class="fa fa-check"></i><b>10.5</b> Usos de representaciones distribuidas</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="t-sne-y-reducción-de-dimensionalidad.html"><a href="t-sne-y-reducción-de-dimensionalidad.html"><i class="fa fa-check"></i><b>11</b> t-SNE y reducción de dimensionalidad</a>
<ul>
<li class="chapter" data-level="" data-path="t-sne-y-reducción-de-dimensionalidad.html"><a href="t-sne-y-reducción-de-dimensionalidad.html#ejemplo-34"><i class="fa fa-check"></i>Ejemplo</a></li>
<li class="chapter" data-level="11.0.1" data-path="t-sne-y-reducción-de-dimensionalidad.html"><a href="t-sne-y-reducción-de-dimensionalidad.html#sne"><i class="fa fa-check"></i><b>11.0.1</b> SNE</a></li>
<li class="chapter" data-level="11.0.2" data-path="t-sne-y-reducción-de-dimensionalidad.html"><a href="t-sne-y-reducción-de-dimensionalidad.html#minimización-para-sne"><i class="fa fa-check"></i><b>11.0.2</b> Minimización para SNE</a></li>
<li class="chapter" data-level="" data-path="t-sne-y-reducción-de-dimensionalidad.html"><a href="t-sne-y-reducción-de-dimensionalidad.html#ejemplo-35"><i class="fa fa-check"></i>Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/felipegonzalez/metodos-analiticos-mcd-2022" target="blank">Repositorio de Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Métodos analíticos, ITAM 2022</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-de-lenguaje-y-n-gramas" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Modelos de lenguaje y n-gramas</h1>
<p>Los <strong>modelos de lenguaje</strong> son
una parte fundamental de varias tareas de NLP (procesamiento de
lenguaje natural), como reconocimiento de lenguaje hablado,
reconocimiento de lenguaje escrito, traducción automática,
corrección de ortografía, sistemas de predicción de escritura,
etc. (ver <span class="citation">(<a href="#ref-jurafsky" role="doc-biblioref">Jurafsky and Martin 2000</a>)</span>, capítulo 4, o en la nueva edición
el <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">capítulo 3</a>
).</p>

<div class="resumen">
<p>Un <strong>modelo del lenguaje</strong> de tipo estadístico es una asignación de
probabilidades <span class="math inline">\(P(W)\)</span> a cada posible frase del lenguaje
<span class="math inline">\(W = w_1 w_2 w_3 \cdots w_n\)</span>.</p>
</div>
<p>Estos modelos del lenguaje están diseñados para
resolver distintas tareas particulares y estimar probabilidades particulares
de interés, de modo que hay muchas maneras de entrenar estos modelos.</p>
<p>Comenzaremos por entender métodos básicos para construir estos modelos,
como conteo de <em>n-gramas</em>, y consideraremos métodos modernos que se basan
en <em>representaciones distribuidas</em>.</p>
<div id="ejemplo-modelo-de-canal-ruidoso" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Ejemplo: Modelo de canal ruidoso</h2>
<p>El modelo del canal ruidoso muestra una situación general en la que los modelos
del lenguaje son importantes:</p>

<div class="resumen">
<p><strong>Canal ruidoso</strong></p>
<p>En el modelo del canal ruidoso tratamos mensajes recibidos como si fueran <em>distorsionados</em> o transformados al pasar por un canal de comunicación ruidoso (por ejemplo, escribir en el celular).</p>
<p>La tarea que queremos resolver con este modelo es
<strong>inferir</strong> la palabra o texto correctos a partir de</p>
<ul>
<li>Un modelo de distorsión o transformación (modelo del canal)</li>
<li>Un modelo del lenguaje.
</div></li>
</ul>
<p>Ahora veremos por qué necesitamos estas dos partes. Supongamos que recibimos
un mensaje codificado o transformado <span class="math inline">\(X\)</span> (quizá texto con errores,
o sonido, o una página escrita), y quisiéramos recuperar el mensaje original <span class="math inline">\(W\)</span>
(sucesión de palabras en texto). Este problema lo podemos enfocar como sigue:</p>
<ul>
<li>Quisiéramos calcular, para cada mensaje <strong>en texto</strong> <span class="math inline">\(W\)</span> la probabilidad</li>
</ul>
<p><span class="math display">\[P(W|X).\]</span></p>
<p>Propondríamos entonces como origen el texto <span class="math inline">\(W^*\)</span> que maximiza esta probabilidad condicional:</p>
<p><span class="math display">\[W^* = argmax_W P(W|X),\]</span></p>
<p>que en principio es un máximo sobre todas las posibles frases del lenguaje.</p>
<p>¿Cómo construimos esta probabilidad condicional? Tenemos que
para cada posible frase <span class="math inline">\(W\)</span>,</p>
<p><span class="math display">\[P(W|X) = \frac{P(X|W)P(W)}{P(X)},\]</span></p>
<p>así que podemos escribir (<span class="math inline">\(X\)</span> es constante)</p>
<p><span class="math display">\[ W^* = argmax_W P(X|W)P(W).\]</span></p>
<p>Esta forma tiene dos partes importantes:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Verosimilitud</strong>: la probabilidad <span class="math inline">\(P(X|W)\)</span> de observar el mensaje transfromado <span class="math inline">\(X\)</span> dado que el mensaje es <span class="math inline">\(W\)</span>. Este es el <strong>modelo del canal</strong> (o <strong>modelo de errores</strong>), que nos dice cómo ocurren errores o transformaciones <span class="math inline">\(X\)</span> cuando se pretende comunicar el mensaje <span class="math inline">\(W\)</span>.</p></li>
<li><p><strong>Inicial</strong> o <strong>previa</strong>: La probabilidad <span class="math inline">\(P(W)\)</span> de observar el mensaje <span class="math inline">\(W\)</span> en el contexto actual. Esto depende más del lenguaje que del canal, y le llamamos el <strong>modelo del lenguaje</strong>.</p></li>
<li><p>Nótese que con estas dos partes tenemos un modelo generativo para mensajes del canal ruidoso: primero seleccionamos un texto mediante el modelo de lenguaje, con las probabilidades <span class="math inline">\(P(W)\)</span>, y dado el mensaje
construimos el mensaje recibido según las probabilidades <span class="math inline">\(P(X|W)\)</span>.</p></li>
</ol>
<div id="ejemplos" class="section level4 unnumbered">
<h4>Ejemplos</h4>
<p>Supongamos que recibimos el mensaje <span class="math inline">\(X=\)</span>“Estoy a días minutos,”
y supongamos que tenemos tres frases en nuestro lenguaje:</p>
<p><span class="math inline">\(W_1=\)</span>“Estoy a veinte minutos,” <span class="math inline">\(W_2=\)</span>“Estoy a diez minutos,” y <span class="math inline">\(W_3\)</span>= “No voy a llegar,” y <span class="math inline">\(W_4\)</span>=“Estoy a tías minutos.” Supongamos que las probabilidades de cada una, dadas por el modelo de lenguaje, son
(independientemente del mensaje recibido):</p>
<table>
<thead>
<tr class="header">
<th align="left">W</th>
<th align="right">P(W)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(W_1\)</span></td>
<td align="right">1e-03</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_2\)</span></td>
<td align="right">1e-03</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(W_3\)</span></td>
<td align="right">8e-03</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_4\)</span></td>
<td align="right">1e-06</td>
</tr>
</tbody>
</table>
<p>Ahora supongamos que el modelo del canal (digamos que sabemos el mecanismo mediante el cual se
escriben los mensajes de texto) nos da:</p>
<table>
<thead>
<tr class="header">
<th align="left">W</th>
<th align="right">P(W)</th>
<th align="right">P(X|W)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(W_1\)</span></td>
<td align="right">1e-03</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_2\)</span></td>
<td align="right">1e-03</td>
<td align="right">0.12</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(W_3\)</span></td>
<td align="right">8e-03</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_4\)</span></td>
<td align="right">1e-06</td>
<td align="right">0.05</td>
</tr>
</tbody>
</table>
<p>Obsérvese que la probabilidad condicional más alta es la segunda, y en
este modelo es imposible que <span class="math inline">\(W_3\)</span> se transforme en <span class="math inline">\(X\)</span> bajo el canal ruidoso. Multiplicando estas dos probabilidades obtenemos:</p>
<table>
<thead>
<tr class="header">
<th align="left">W</th>
<th align="right">P(W)</th>
<th align="right">P(X|W)</th>
<th align="right">P(X|W)P(W)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(W_1\)</span></td>
<td align="right">2e-03</td>
<td align="right">0.01</td>
<td align="right">0.00002</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_2\)</span></td>
<td align="right">1e-03</td>
<td align="right">0.12</td>
<td align="right">0.00012</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(W_3\)</span></td>
<td align="right">8e-03</td>
<td align="right">0.00</td>
<td align="right">0.00000</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(W_4\)</span></td>
<td align="right">1e-06</td>
<td align="right">0.05</td>
<td align="right">0.00000</td>
</tr>
</tbody>
</table>
<p>de modo que escogeríamos la segunda frase (máxima probabilidad condicional) como la interpretación de
“Estoy a días minutos.”</p>
<p>Nótese que <span class="math inline">\(P(X|W_3)\)</span> en particular es muy bajo,
porque es poco posible que el canal distosione “No voy a llegar”
a “Estoy a días minutos.” Por otro lado <span class="math inline">\(P(W_4)\)</span> también
es muy bajo, pues la frase <span class="math inline">\(W_4\)</span> tiene probabilidad muy baja de
ocurrir.</p>
</div>
<div id="ejercicio-11" class="section level4 unnumbered">
<h4>Ejercicio</h4>
<p>Piensa cómo sería el modelo de canal ruidoso <span class="math inline">\(P(X|W)\)</span> si nuestro problema fuera reconocimiento de frases habladas o escritas, o en traducción entre dos lenguajes.</p>
</div>
</div>
<div id="corpus-y-vocabulario" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Corpus y vocabulario</h2>
<p>En los ejemplos vistos arriba, vemos que necesitamos definir qué son
las <em>palabras</em> <span class="math inline">\(w_i\)</span>, qué lenguaje estamos considerando, y cómo estimamos las probabilidades.</p>

<div class="comentario">
<ul>
<li>Un <strong>corpus</strong> es una colección de textos (o habla) del lenguaje que nos interesa.</li>
<li>El <strong>vocabulario</strong> es una colección de palabras que ocurren en el <strong>corpus</strong> (o más general, en el lenguaje).</li>
<li>La definición de <strong>palabra</strong> (token) depende de la tarea de NLP que nos interesa.
</div></li>
</ul>
<p>Algunas decisiones que tenemos que tomar, por ejemplo:</p>
<ul>
<li>Generalmente, cada palabra está definida como una unidad separada
por espacios o signos de puntuación.</li>
<li>Los signos de puntuación pueden o no considerarse como palabras.</li>
<li>Pueden considerarse palabras distintas las que tienen mayúscula y las que no (por ejemplo, para reconocimiento de lenguaje hablado no nos
interesan las mayúsculas).</li>
<li>Pueden considerarse palabras distintas las que están escritas incorrectamente, o no.</li>
<li>Pueden considerarse plurales como palabras distintas, formas en masculino/femenino, etc. (por ejemplo, en clasificación de textos quizá
sólo nos importa saber la raíz en lugar de la forma completa de la palabra).</li>
<li>Comienzos y terminación de oraciones pueden considerarse como
“palabras” (por ejemplo, en reconocimiento de texto hablado).</li>
</ul>

<div class="resumen">
Al proceso que encuentra todas las palabras en un texto se le
llama <strong>tokenización</strong> o <strong>normalización de texto</strong>. Los <strong>tokens</strong>
de un texto son las ocurrencias en el texto de las palabras
en el vocabuario.
</div>
<p>En los ejemplos que veremos a continuación consideraremos las
siguiente normalización:</p>
<ul>
<li>Consideramos como una palabra el comienzo y el fin de una oración.</li>
<li>Normalizamos el texto a minúsculas.</li>
<li>No corregimos ortografía, y consideramos las palabras en la forma que ocurren.</li>
<li>Consideramos signos de puntuación como palabras.</li>
</ul>
<p>El <strong>vocabulario</strong> es el conjunto de todas las palabras posibles en nuestros
textos. Lo denotaremos como <span class="math inline">\(w^1, w^2, \ldots, w^N\)</span>, para un vocabulario de <span class="math inline">\(N\)</span>
distintas palabras o tokens.</p>
</div>
<div id="modelos-de-lenguaje-n-gramas" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Modelos de lenguaje: n-gramas</h2>
<p>Consideremos cómo construiríamos las probabilidades <span class="math inline">\(P(W)\)</span>, de manera que
reflejen la ocurrencia de frases en nuestro lenguaje. Escribimos
<span class="math display">\[W=w_1 w_2 w_3 \cdots w_n,\]</span>
donde <span class="math inline">\(w_i\)</span> son las palabras que contienen el texto <span class="math inline">\(W\)</span>.</p>
<p>Aquí nos enfrentamos al primer problema:</p>
<ul>
<li>Dada la variedad de frases que potencialmente hay en el lenguaje,
no tiene mucho sentido intentar estimar o enumerar
directamente estas probabilidades. Por ejemplo, si intentamos
algo como intentar ver una colección de ejemplos del lenguaje,
veremos que el número de frases es muy grande, y la mayor
parte de los textos o frases posibles en el lenguaje no
ocurren en nuestra colección (por más grande que sea la
colección).</li>
</ul>
<p>Para tener un acercamiento razonable, necesitamos considerar
un modelo <span class="math inline">\(P(W)\)</span> con más estructura o supuestos. Hay varias maneras de hacer esto,
y un primer acercamiento
consiste en considerar solamente <em>el contexto más inmediato</em> de
cada palabra. Es decir, la probabilidad de ocurrencia de palabras en una frase
generalmente se puede evaluar con un contexto relativamente
chico (palabras cercanas) y no es necesario considerar la frase completa.</p>
<p>Consideramos entonces la regla del producto:</p>
<p><span class="math display">\[P(w_1 w_2 w_3 \cdots w_n) = P(w_1)P(w_2|w_1)P(w_3|w_1 w_2) \cdots
P(w_n|w_1 w_2 w_3 \cdots w_{n-1})\]</span>
Y observamos entonces que basta con calcular las probabilidades
condicionales de la siguiente palabra:
<span class="math display">\[P(w_{m+1}|w_1\cdots w_m)\]</span>
para cualquier conjunto de palabras <span class="math inline">\(w,w_1,\ldots, w_m\)</span>.</p>
<p>A estas <span class="math inline">\(w,w_1,\ldots, w_m\)</span> palabras que ocurren justo antes de <span class="math inline">\(w\)</span> les
llamamos el <em>contexto</em> de <span class="math inline">\(w\)</span> en la frase. Por la regla
del producto, podemos ver entonces nuestro problema como uno
de <strong>predecir la palabra siguiente</strong>, dado el contexto. Por ejemplo,
si tenemos la frase “como tengo examen entonces voy a ….” la probabilidad
de observar “estudiar” o “dormir” debe ser más alta que la de “gato.”</p>

<div class="resumen">
<ul>
<li>A una sucesión de longitud <span class="math inline">\(n\)</span> de palabras <span class="math inline">\(w_1w_2\cdots w_n\)</span> le
llamamos un <strong>n-grama</strong> de nuestro lenguaje.
</div></li>
</ul>
<p>Igualmente, calcular todas estas condicionales contando tampoco es factible,
pues si el vocabulario es de tamaño <span class="math inline">\(V\)</span>, entonces los contextos
posibles son de tamaño <span class="math inline">\(V^m\)</span>, el cual es un número muy grande
incluso para <span class="math inline">\(m\)</span> no muy grande. Pero
podemos hacer una simplificación: suponer
que la predicción será suficientemente buena si limitamos el contexto de la siguiente
palabra a <span class="math inline">\(n\)</span>-gramas, para una <span class="math inline">\(n\)</span> relativamente chica.</p>
<p>Por ejemplo, para <strong>bigramas</strong>, solo nos interesa calcular
<span class="math display">\[P(w_m|w_{m-1}),\]</span></p>
<p>la dependencia hacia atrás contando solo la palabra anteriore. Simplificaríamos la formula
de arriba como sigue:</p>
<p><span class="math display">\[P(w_1 w_2 w_3 \cdots w_n) = P(w_1)P(w_2|w_1)P(w_3|w_2) P(w_4|w_3)\cdots
P(w_n| w_{n-1})\]</span></p>
<p>Este se llama modelo basado en <strong>bigramas</strong>. En el caso más simple, establecemos que
la ocurrencia de una palabra es independiente de su contexto:</p>
<p><span class="math display">\[P(w|w_1\cdots w_{n-1}) = P(w)\]</span></p>
<p>de forma que el modelo del lenguaje se simplifica a:</p>
<p><span class="math display">\[P(w_1 w_2 w_3 \cdots w_n) = P(w_1)P(w_2)P(w_3) \cdots P(w_n)\]</span></p>
<p>A este modelo le llamamos el modelo de <strong>unigramas</strong>.</p>
<div id="modelo-generativo-de-n-gramas" class="section level3" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Modelo generativo de n-gramas</h3>
<p>Para que estos modelos den realmente una distribución de probabilidad
sobre todas las frases posibles, es necesario tener también un modelo de la longitud de las frases.
Una manera es definir <span class="math inline">\(P(N)\)</span>, que es la distribución sobre la longitud de frase. Sin embargo,
la manera más común es introducir dos símbolos nuevos</p>
<ul>
<li>Para inicio de frase usamos <span class="math inline">\(&lt;s&gt;\)</span></li>
<li>Para fin de frase usamos <span class="math inline">\(&lt;/s&gt;\)</span></li>
</ul>
<p>De esta manera, el proceso de generación de frases en unigramas es el siguiente:</p>
<ol style="list-style-type: decimal">
<li>Comenzamos con el símbolo <span class="math inline">\(&lt;s&gt;\)</span>.</li>
</ol>
<p>Comenzando con <span class="math inline">\(i = 1\)</span>:</p>
<ol start="2" style="list-style-type: decimal">
<li>Escogemos una palabra <span class="math inline">\(w_i\)</span> del vocabulario <span class="math inline">\(w^1\)</span> a <span class="math inline">\(w^N\)</span> y <span class="math inline">\(&lt;/s&gt;\)</span>. Estas probabilidades las denotamos como
<span class="math inline">\(P(w^1), P(w^2),\ldots, P(w^N)\)</span> y <span class="math inline">\(P(&lt;/s&gt;)\)</span>, y todas estas probabilides deben sumar 1.</li>
<li>Si escogimos <span class="math inline">\(&lt;/s&gt;\)</span>, terminamos la frase. En otro caso, regresamos a 2 con <span class="math inline">\(i=i+1\)</span>.</li>
</ol>
<p>La probabilidad de escoger la frase <span class="math inline">\(P(&lt;s&gt;w_1w_2\cdots w_n&lt;/s&gt;)\)</span> es entonces</p>
<p><span class="math inline">\(P(&lt;s&gt;w_1w_2\cdots w_n&lt;/s&gt;) = P(w_1)P(w_2)\cdots P(w_n)P(&lt;/s&gt;).\)</span></p>
<p>Por construcción, las probabilidades sobre todas las frases suman 1. Necesitamos definir
todas las probabilidades
<span class="math display">\[P(w)\]</span>
donde <span class="math inline">\(w\)</span> es una palabra o <span class="math inline">\(&lt;/s&gt;\)</span>.</p>
<div id="ejercicio-12" class="section level4 unnumbered">
<h4>Ejercicio</h4>
<p>Supón que solo hay dos palabras en nuestro vocabulario <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>. Calcula cuál es la probabilidad
de obtener una frase de tamaño 1, 2, 3, etc. Verifica que estas probabilidades suman 1.
(supón que están definidos <span class="math inline">\(p(a),p(b),p(&lt;/s&gt;)\)</span> y suman 1).</p>
<hr />
<p>Para <strong>bigramas</strong> el proceso de generación es el siguiente:</p>
<ol style="list-style-type: decimal">
<li>Comenzamos con el símbolo <span class="math inline">\(&lt;s&gt;\)</span>.<br />
</li>
<li>Escogemos una palabra <span class="math inline">\(w_1\)</span> según las probabilidades ya definidas</li>
</ol>
<p><span class="math display">\[P(w^1|&lt;s&gt;), P(w^2|&lt;s&gt;), \ldots, P(w^N|&lt;s&gt;)\]</span></p>
<p>sobre el vocabulario. Estas probabilidades suman 1.</p>
<p>Comenzando con <span class="math inline">\(i=1\)</span>,</p>
<ol start="3" style="list-style-type: decimal">
<li>Escogemos una palabra <span class="math inline">\(w_{i+1}\)</span> según las probabilidades ya definidas</li>
</ol>
<p><span class="math display">\[P(w^1|w_i), P(w^2|w_i), \ldots, P(w^N|w_i)\]</span></p>
<p>sobre el vocabulario. Estas probabilidades suman 1.
4. Si la palabra escogida es <span class="math inline">\(&lt;/s&gt;\)</span> terminamos. Si no, repetimos 3 con <span class="math inline">\(i=i+1\)</span>.</p>
<p>La probabilidad de una frase dada dado el modelo de bigramas es entonces:</p>
<p><span class="math display">\[P(&lt;s&gt;w_1\cdots w_n &lt;/s&gt;) = P(w_1|&lt;s&gt;)P(w_2|w_1)P(w_3|w_2)  P(w_4|w_3) \cdots P(w_n|w_{n-1})P(&lt;/s&gt;|w_n).\]</span></p>
<p>Por definición, la suma de probabilidades sobre todas las frases es 1. Necesitamos definir entonces
todas la probablidades
<span class="math display">\[p(w|z),\]</span>
donde <span class="math inline">\(z\)</span> es una palabra o <span class="math inline">\(&lt;s&gt;\)</span>, y <span class="math inline">\(w\)</span> es una palabra o <span class="math inline">\(&lt;/s&gt;\)</span>.</p>
<p>Para <strong>trigramas</strong> podemos agregar un símbolo <span class="math inline">\(&lt;s&gt;&lt;s&gt;\)</span> al inicio. Esto nos permite definir de manera
simple el proceso de generación como sigue:</p>
<ol style="list-style-type: decimal">
<li>Comenzamos con los dos símbolos <span class="math inline">\(&lt;s&gt;&lt;s&gt;\)</span>.</li>
</ol>
<p>Comenzando con <span class="math inline">\(i=1\)</span>:</p>
<ol start="2" style="list-style-type: decimal">
<li>Cada palabra nueva <span class="math inline">\(w_i\)</span> se escoge según las probabilidades <span class="math inline">\(P(w|w_1w_2)\)</span> sobre <span class="math inline">\(w\)</span> en el vocabulario
(<span class="math inline">\(w^1\)</span>, <span class="math inline">\(w^N\)</span>). Estas probabilidades deben sumar uno.</li>
<li>Terminamos cuando la palabra nueva escogida es <span class="math inline">\(&lt;/s&gt;\)</span>. Si no, repetimos 2 con <span class="math inline">\(i=i+1\)</span></li>
</ol>
<p>Nótese que en la primera elección escogemos de <span class="math inline">\(p(w|&lt;s&gt;&lt;s&gt;)\)</span> y luego de <span class="math inline">\(p(w|&lt;s&gt; w^1)\)</span>.</p>
<p>La probabilidad de una frase dada dado el modelo de bigramas es entonces:</p>
<p><span class="math display">\[P(&lt;s&gt;&lt;s&gt;w_1\cdots w_n &lt;/s&gt;) = P(w_1|&lt;s&gt;&lt;s&gt;)P(w_2|&lt;s&gt;w_1)P(w_3|w_1w_2)  P(w_4|w_2w_3) \cdots P(&lt;/s&gt;|w_{n-1}w_n).\]</span></p>
<hr />
<p>El modelo de unigramas
puede ser deficiente para algunas aplicaciones,
y las probabilidades calculadas con este modelo pueden estar muy
lejos ser razonables. Por ejemplo, el modelo de unigramas da la
misma probabilidad a la frase <em>un día</em> y a la frase <em>día un</em>, aunque
la ocurrencia en el lenguaje de estas dos frases es muy distinta.</p>
</div>
<div id="ejemplo-28" class="section level4 unnumbered">
<h4>Ejemplo</h4>
<p>Supongamos que consideramos el modelo de bigramas, y queremos calcular
la probabilidad de la frase “el perro corre.” Agregamos inicio y final
de frase para obtener <span class="math inline">\(&lt;s&gt; el \, perro \, corre &lt;/s&gt;\)</span> Y ahora pondríamos:
<span class="math display">\[P(el,perro,corre) = P(el|&lt;s&gt;)P(perro \,|\, el)P(corre \,|\, perro)P(&lt;/s&gt;|corre)\]</span>
Nótese que aún para frases más largas, sólo es necesario definir
<span class="math inline">\(P(w|z)\)</span> para cada para de palabras del vocabulario <span class="math inline">\(w,z\)</span>, lo cual
es un simplificación considerable.</p>
<hr />
<p>La probabilidad de bigramas también se puede escribir como, usando las convenciones de
caracteres de inicio y de final de frase, como</p>
<p><span class="math display">\[P(w_1\cdots w_n) = \prod_{j=1}^n P(w_j | w_{j -1}).\]</span></p>
<p>Y así podemos seguir. Por ejemplo, con el <strong>modelo de trigramas</strong>,</p>
<p><span class="math display">\[P(w_1\cdots w_n) = P(w_3|w_1w_2)  P(w_4|w_2w_3) \cdots P(w_n| w_{n-2} w_{n-1}).\]</span></p>
<p>En este caso, usamos dos símbolos de inicio de frase <span class="math inline">\(&lt;s&gt; &lt;s&gt;\)</span> para que la fórmula tenga sentido.</p>
<p><strong>Observación</strong>: los modelos de n-gramas son aproximaciones útiles, y fallan en la modelación de dependencias de larga distancia. Por ejemplo, en la frase “Tengo un gato en mi casa, y es de tipo persa” tendríamos que considerar n-gramas imprácticamente largos para modelar correctamente la ocurrencia de la palabra “persa” al final de la oración.</p>
</div>
</div>
</div>
<div id="modelo-de-n-gramas-usando-conteos" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Modelo de n-gramas usando conteos</h2>
<p>Supongamos que tenemos una colección de textos o frases del lenguaje
que nos interesa.
¿Cómo podemos estimar las probabilidades del tipo <span class="math inline">\(P(w|a)\)</span> <span class="math inline">\(P(w|a,b)\)</span>?</p>
<p>El enfoque más simple es estimación por máxima verosimilitud, que
en esto caso implica estimar con conteos de ocurrencia
en el lenguaje. Si queremos
estimar <span class="math inline">\(P(w|z)\)</span> (modelo de bigramas), entonces tomamos nuestra colección, y calculamos:</p>
<ul>
<li><span class="math inline">\(N(z,w)\)</span> = número de veces que aparece <span class="math inline">\(z\)</span> seguida de <span class="math inline">\(w\)</span></li>
<li><span class="math inline">\(N(z)\)</span> = número de veces que aparece <span class="math inline">\(z\)</span>.</li>
<li><span class="math inline">\(P(w|z) = \frac{N(z,w)}{N(z)}\)</span></li>
</ul>
<p>Nótese que estas probabilidades en general son chicas (pues el
vocabulario es grande), de forma que conviene usar las log probabilidades
para hacer los cálculos y evitar <em>underflows</em>. Calculamos entonces usando:</p>
<ul>
<li><span class="math inline">\(\log{P(w|z)} = \log{N(zw)} - \log{N(z)}\)</span></li>
</ul>
<p>¿Cómo se estimarían las probabilidades para el modelo de unigramas
y trigramas?</p>
<div id="ejercicio-13" class="section level4 unnumbered">
<h4>Ejercicio</h4>
<p>Considera la colección de textos “un día muy soleado,”
“un día muy lluvioso,” “un ejemplo muy simple de bigramas.” Estima
las probabilidades <span class="math inline">\(P(muy|&lt;s&gt;)\)</span>, <span class="math inline">\(P(día | un)\)</span>, <span class="math inline">\(P(simple | muy)\)</span> usando
conteos.</p>
</div>
<div id="ejemplo-29" class="section level4 unnumbered">
<h4>Ejemplo</h4>
<p>Comenzamos por limpiar nuestra colección de texto, creando también <em>tokens</em> adicionales para signos de puntuación. En este caso solo tenemos dos textos:</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-1" aria-hidden="true" tabindex="-1"></a>normalizar <span class="ot">&lt;-</span> <span class="cf">function</span>(texto, <span class="at">vocab =</span> <span class="cn">NULL</span>){</span>
<span id="cb772-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># minúsculas</span></span>
<span id="cb772-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-3" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">tolower</span>(texto)</span>
<span id="cb772-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># varios ajustes</span></span>
<span id="cb772-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-5" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">s+&quot;</span>, <span class="st">&quot; &quot;</span>, texto)</span>
<span id="cb772-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-6" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">.[^0-9]&quot;</span>, <span class="st">&quot; _punto_ &quot;</span>, texto)</span>
<span id="cb772-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-7" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot; _s_ $&quot;</span>, <span class="st">&quot;&quot;</span>, texto)</span>
<span id="cb772-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-8" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">.&quot;</span>, <span class="st">&quot; _punto_ &quot;</span>, texto)</span>
<span id="cb772-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-9" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;[«»¡!¿?-]&quot;</span>, <span class="st">&quot;&quot;</span>, texto) </span>
<span id="cb772-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-10" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;;&quot;</span>, <span class="st">&quot; _punto_coma_ &quot;</span>, texto) </span>
<span id="cb772-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-11" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">:&quot;</span>, <span class="st">&quot; _dos_puntos_ &quot;</span>, texto) </span>
<span id="cb772-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-12" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">,[^0-9]&quot;</span>, <span class="st">&quot; _coma_ &quot;</span>, texto)</span>
<span id="cb772-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-13" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;</span><span class="sc">\\</span><span class="st">s+&quot;</span>, <span class="st">&quot; &quot;</span>, texto)</span>
<span id="cb772-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-14" aria-hidden="true" tabindex="-1"></a>  texto</span>
<span id="cb772-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb772-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-17" aria-hidden="true" tabindex="-1"></a>corpus_mini <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Este es un ejemplo: el perro corre, el gato escapa. Este es un número 3.1416, otro número es 1,23.&quot;</span>, <span class="st">&quot;Este   es otro ejemplo.  &quot;</span> )</span>
<span id="cb772-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb772-18" aria-hidden="true" tabindex="-1"></a><span class="fu">normalizar</span>(corpus_mini)</span></code></pre></div>
<pre><code>## [1] &quot;este es un ejemplo _dos_puntos_ el perro corre _coma_ el gato escapa _punto_ este es un número 3 _punto_ 1416 _coma_ otro número es 1,23 _punto_ &quot;
## [2] &quot;este es otro ejemplo _punto_ &quot;</code></pre>
<p>Y ahora construimos, por ejemplo, los bigramas que ocurren en cada texto</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-1" aria-hidden="true" tabindex="-1"></a>ejemplo <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">txt =</span> corpus_mini) <span class="sc">|&gt;</span></span>
<span id="cb774-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-2" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">id =</span> <span class="fu">row_number</span>()) <span class="sc">|&gt;</span></span>
<span id="cb774-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-3" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">txt =</span> <span class="fu">normalizar</span>(txt)) </span>
<span id="cb774-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-4" aria-hidden="true" tabindex="-1"></a>bigrams_ejemplo <span class="ot">&lt;-</span> ejemplo <span class="sc">|&gt;</span> </span>
<span id="cb774-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-5" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">unnest_tokens</span>(bigramas, txt, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>, </span>
<span id="cb774-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-6" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">n =</span> <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb774-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-7" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">group_by</span>(bigramas) <span class="sc">|&gt;</span> <span class="fu">tally</span>()</span>
<span id="cb774-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb774-8" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(bigrams_ejemplo)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">bigramas</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>coma</em> el</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em> otro</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><em>dos_puntos</em> el</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em> 1416</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em> este</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">1,23 <em>punto</em></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">1416 <em>coma</em></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">3 <em>punto</em></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">corre <em>coma</em></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">ejemplo <em>dos_puntos</em></td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">ejemplo <em>punto</em></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">el gato</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">el perro</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">es 1,23</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">es otro</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">es un</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="left">escapa <em>punto</em></td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">este es</td>
<td align="right">3</td>
</tr>
<tr class="odd">
<td align="left">gato escapa</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">número 3</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">número es</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">otro ejemplo</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">otro número</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">perro corre</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">un ejemplo</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">un número</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="notas-de-periódico-modelo-de-n-gramas-simples." class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Notas de periódico: modelo de n-gramas simples.</h2>
<p>En los siguientes ejemplos, utilizaremos una colección de
noticias cortas en español (de España).</p>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb775-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb775-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-2" aria-hidden="true" tabindex="-1"></a>ruta <span class="ot">&lt;-</span> <span class="st">&quot;../datos/noticias/ES_Newspapers.txt&quot;</span></span>
<span id="cb775-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">file.exists</span>(ruta)){</span>
<span id="cb775-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-4" aria-hidden="true" tabindex="-1"></a>    periodico <span class="ot">&lt;-</span> </span>
<span id="cb775-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">read_lines</span>(<span class="at">file=</span> <span class="st">&quot;https://es-noticias.s3.amazonaws.com/Es_Newspapers.txt&quot;</span>,</span>
<span id="cb775-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">progress =</span> <span class="cn">FALSE</span>)</span>
<span id="cb775-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">write_lines</span>(periodico, ruta)</span>
<span id="cb775-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-8" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb775-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-9" aria-hidden="true" tabindex="-1"></a>    periodico <span class="ot">&lt;-</span> <span class="fu">read_lines</span>(<span class="at">file=</span> ruta,</span>
<span id="cb775-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">progress =</span> <span class="cn">FALSE</span>)</span>
<span id="cb775-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb775-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb775-12" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(periodico)</span></code></pre></div>
<pre><code>## [1] 309918</code></pre>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb777-1" aria-hidden="true" tabindex="-1"></a>periodico[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] &quot;En este sentido, señala que «no podemos consentir» que se repita «el malogrado caso del Centro de Transportes de Benavente, donde la falta de control ha supuesto un cúmulo de irregularidades que rozan lo delictivo».&quot;                                                    
## [2] &quot;\&quot;Cuando acabe la experiencia con el Inter no me quedaré en Italia, sino que espero ir a España, porque mi objetivo es ganar los títulos de los tres campeonatos más competitivos del mundo\&quot;, afirmó el que fuera entrenador del Barcelona B, y añadió: \&quot;me falta Liga\&quot;.&quot;</code></pre>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb779-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb779-1" aria-hidden="true" tabindex="-1"></a>periodico_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">txt =</span> periodico) <span class="sc">|&gt;</span></span>
<span id="cb779-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb779-2" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">id =</span> <span class="fu">row_number</span>()) <span class="sc">|&gt;</span></span>
<span id="cb779-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb779-3" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">txt =</span> <span class="fu">normalizar</span>(txt)) </span></code></pre></div>
<p>Adicionalmente, seleccionamos una muestra para hacer las
demostraciones (puedes correrlo con todo el corpus):</p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb780-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb780-2" aria-hidden="true" tabindex="-1"></a>muestra_ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(periodico_df), <span class="fl">1e5</span>)</span>
<span id="cb780-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb780-3" aria-hidden="true" tabindex="-1"></a>periodico_m <span class="ot">&lt;-</span> periodico_df[muestra_ind, ]</span></code></pre></div>
<p>Y calculamos las frecuencias de todos unigramas, bigramas y trigramas:</p>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb781-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-1" aria-hidden="true" tabindex="-1"></a>conteo_ngramas <span class="ot">&lt;-</span> <span class="cf">function</span>(corpus, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">vocab_df =</span> <span class="cn">NULL</span>){</span>
<span id="cb781-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-2" aria-hidden="true" tabindex="-1"></a>  token_nom <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&#39;w_n_&#39;</span>, <span class="fu">rev</span>(<span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span>n)) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb781-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-3" aria-hidden="true" tabindex="-1"></a>  token_cond <span class="ot">&lt;-</span> token_nom[<span class="sc">-</span><span class="fu">length</span>(token_nom)]</span>
<span id="cb781-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># añadir inicio de frases</span></span>
<span id="cb781-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-5" aria-hidden="true" tabindex="-1"></a>  inicio <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="fu">rep</span>(<span class="st">&quot;_s_ &quot;</span>, n <span class="sc">-</span> <span class="dv">1</span>), <span class="at">collapse =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb781-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># añadir fin de frases</span></span>
<span id="cb781-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-7" aria-hidden="true" tabindex="-1"></a>  fin <span class="ot">&lt;-</span> <span class="st">&quot; _ss_&quot;</span></span>
<span id="cb781-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-8" aria-hidden="true" tabindex="-1"></a>  ngramas_df <span class="ot">&lt;-</span> corpus <span class="sc">|&gt;</span></span>
<span id="cb781-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-9" aria-hidden="true" tabindex="-1"></a>                <span class="fu">mutate</span>(<span class="at">txt =</span> <span class="fu">paste</span>(inicio, txt, fin)) <span class="sc">|&gt;</span></span>
<span id="cb781-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-10" aria-hidden="true" tabindex="-1"></a>                <span class="fu">unnest_tokens</span>(ngrama, txt, <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="at">n =</span> n) </span>
<span id="cb781-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-11" aria-hidden="true" tabindex="-1"></a>  frec_ngramas <span class="ot">&lt;-</span> ngramas_df <span class="sc">|&gt;</span> <span class="fu">group_by</span>(ngrama) <span class="sc">|&gt;</span></span>
<span id="cb781-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-12" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">summarise</span>(<span class="at">num =</span> <span class="fu">length</span>(ngrama)) <span class="sc">|&gt;</span></span>
<span id="cb781-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-13" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">separate</span>(ngrama, token_nom, <span class="at">sep=</span><span class="st">&quot; &quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb781-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-14" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">group_by</span>(<span class="fu">across</span>(<span class="fu">all_of</span>(token_cond))) <span class="sc">|&gt;</span></span>
<span id="cb781-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-15" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">mutate</span>(<span class="at">denom =</span> <span class="fu">sum</span>(num)) <span class="sc">|&gt;</span></span>
<span id="cb781-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-16" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span></span>
<span id="cb781-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-17" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">mutate</span>(<span class="at">log_p =</span> <span class="fu">log</span>(num) <span class="sc">-</span> <span class="fu">log</span>(denom))</span>
<span id="cb781-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-18" aria-hidden="true" tabindex="-1"></a>  frec_ngramas</span>
<span id="cb781-19"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb781-20"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-20" aria-hidden="true" tabindex="-1"></a>mod_uni <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb781-21"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-21" aria-hidden="true" tabindex="-1"></a>mod_bi  <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m, <span class="at">n =</span> <span class="dv">2</span>)</span>
<span id="cb781-22"><a href="modelos-de-lenguaje-y-n-gramas.html#cb781-22" aria-hidden="true" tabindex="-1"></a>mod_tri <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m, <span class="at">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb782-1" aria-hidden="true" tabindex="-1"></a>mod_uni <span class="sc">|&gt;</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(num)) <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="dv">100</span>) <span class="sc">|&gt;</span> knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">w_n_0</th>
<th align="right">num</th>
<th align="right">denom</th>
<th align="right">log_p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">de</td>
<td align="right">426481</td>
<td align="right">6894607</td>
<td align="right">-2.782927</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="right">380344</td>
<td align="right">6894607</td>
<td align="right">-2.897419</td>
</tr>
<tr class="odd">
<td align="left">la</td>
<td align="right">261913</td>
<td align="right">6894607</td>
<td align="right">-3.270482</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="right">248139</td>
<td align="right">6894607</td>
<td align="right">-3.324506</td>
</tr>
<tr class="odd">
<td align="left">el</td>
<td align="right">212825</td>
<td align="right">6894607</td>
<td align="right">-3.478025</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="right">210647</td>
<td align="right">6894607</td>
<td align="right">-3.488311</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="right">183614</td>
<td align="right">6894607</td>
<td align="right">-3.625659</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="right">158689</td>
<td align="right">6894607</td>
<td align="right">-3.771549</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="right">130347</td>
<td align="right">6894607</td>
<td align="right">-3.968295</td>
</tr>
<tr class="even">
<td align="left">los</td>
<td align="right">108758</td>
<td align="right">6894607</td>
<td align="right">-4.149370</td>
</tr>
<tr class="odd">
<td align="left"><em>ss</em></td>
<td align="right">100000</td>
<td align="right">6894607</td>
<td align="right">-4.233325</td>
</tr>
<tr class="even">
<td align="left">del</td>
<td align="right">84899</td>
<td align="right">6894607</td>
<td align="right">-4.397032</td>
</tr>
<tr class="odd">
<td align="left">se</td>
<td align="right">77632</td>
<td align="right">6894607</td>
<td align="right">-4.486515</td>
</tr>
<tr class="even">
<td align="left">las</td>
<td align="right">68042</td>
<td align="right">6894607</td>
<td align="right">-4.618370</td>
</tr>
<tr class="odd">
<td align="left">un</td>
<td align="right">66732</td>
<td align="right">6894607</td>
<td align="right">-4.637810</td>
</tr>
<tr class="even">
<td align="left">por</td>
<td align="right">62876</td>
<td align="right">6894607</td>
<td align="right">-4.697330</td>
</tr>
<tr class="odd">
<td align="left">con</td>
<td align="right">60358</td>
<td align="right">6894607</td>
<td align="right">-4.738201</td>
</tr>
<tr class="even">
<td align="left">una</td>
<td align="right">49207</td>
<td align="right">6894607</td>
<td align="right">-4.942459</td>
</tr>
<tr class="odd">
<td align="left">para</td>
<td align="right">48948</td>
<td align="right">6894607</td>
<td align="right">-4.947736</td>
</tr>
<tr class="even">
<td align="left">no</td>
<td align="right">46051</td>
<td align="right">6894607</td>
<td align="right">-5.008745</td>
</tr>
<tr class="odd">
<td align="left">su</td>
<td align="right">42489</td>
<td align="right">6894607</td>
<td align="right">-5.089250</td>
</tr>
<tr class="even">
<td align="left">ha</td>
<td align="right">41228</td>
<td align="right">6894607</td>
<td align="right">-5.119377</td>
</tr>
<tr class="odd">
<td align="left">al</td>
<td align="right">39885</td>
<td align="right">6894607</td>
<td align="right">-5.152495</td>
</tr>
<tr class="even">
<td align="left">es</td>
<td align="right">35381</td>
<td align="right">6894607</td>
<td align="right">-5.272320</td>
</tr>
<tr class="odd">
<td align="left">lo</td>
<td align="right">27222</td>
<td align="right">6894607</td>
<td align="right">-5.534469</td>
</tr>
<tr class="even">
<td align="left">más</td>
<td align="right">27140</td>
<td align="right">6894607</td>
<td align="right">-5.537486</td>
</tr>
<tr class="odd">
<td align="left">como</td>
<td align="right">26150</td>
<td align="right">6894607</td>
<td align="right">-5.574646</td>
</tr>
<tr class="even">
<td align="left">este</td>
<td align="right">16660</td>
<td align="right">6894607</td>
<td align="right">-6.025484</td>
</tr>
<tr class="odd">
<td align="left">pero</td>
<td align="right">15365</td>
<td align="right">6894607</td>
<td align="right">-6.106403</td>
</tr>
<tr class="even">
<td align="left">sus</td>
<td align="right">14892</td>
<td align="right">6894607</td>
<td align="right">-6.137671</td>
</tr>
<tr class="odd">
<td align="left">han</td>
<td align="right">14145</td>
<td align="right">6894607</td>
<td align="right">-6.189134</td>
</tr>
<tr class="even">
<td align="left">o</td>
<td align="right">13919</td>
<td align="right">6894607</td>
<td align="right">-6.205240</td>
</tr>
<tr class="odd">
<td align="left">esta</td>
<td align="right">12189</td>
<td align="right">6894607</td>
<td align="right">-6.337961</td>
</tr>
<tr class="even">
<td align="left">también</td>
<td align="right">12089</td>
<td align="right">6894607</td>
<td align="right">-6.346199</td>
</tr>
<tr class="odd">
<td align="left">ya</td>
<td align="right">12056</td>
<td align="right">6894607</td>
<td align="right">-6.348932</td>
</tr>
<tr class="even">
<td align="left">dos</td>
<td align="right">11364</td>
<td align="right">6894607</td>
<td align="right">-6.408044</td>
</tr>
<tr class="odd">
<td align="left">años</td>
<td align="right">11314</td>
<td align="right">6894607</td>
<td align="right">-6.412454</td>
</tr>
<tr class="even">
<td align="left">entre</td>
<td align="right">11124</td>
<td align="right">6894607</td>
<td align="right">-6.429390</td>
</tr>
<tr class="odd">
<td align="left">le</td>
<td align="right">11083</td>
<td align="right">6894607</td>
<td align="right">-6.433082</td>
</tr>
<tr class="even">
<td align="left"><em>dos_puntos</em></td>
<td align="right">10785</td>
<td align="right">6894607</td>
<td align="right">-6.460338</td>
</tr>
<tr class="odd">
<td align="left">desde</td>
<td align="right">10293</td>
<td align="right">6894607</td>
<td align="right">-6.507031</td>
</tr>
<tr class="even">
<td align="left">sobre</td>
<td align="right">9659</td>
<td align="right">6894607</td>
<td align="right">-6.570605</td>
</tr>
<tr class="odd">
<td align="left">año</td>
<td align="right">9355</td>
<td align="right">6894607</td>
<td align="right">-6.602584</td>
</tr>
<tr class="even">
<td align="left">si</td>
<td align="right">9324</td>
<td align="right">6894607</td>
<td align="right">-6.605903</td>
</tr>
<tr class="odd">
<td align="left">fue</td>
<td align="right">9224</td>
<td align="right">6894607</td>
<td align="right">-6.616686</td>
</tr>
<tr class="even">
<td align="left">sin</td>
<td align="right">8968</td>
<td align="right">6894607</td>
<td align="right">-6.644832</td>
</tr>
<tr class="odd">
<td align="left">está</td>
<td align="right">8861</td>
<td align="right">6894607</td>
<td align="right">-6.656835</td>
</tr>
<tr class="even">
<td align="left">hasta</td>
<td align="right">8563</td>
<td align="right">6894607</td>
<td align="right">-6.691044</td>
</tr>
<tr class="odd">
<td align="left">todo</td>
<td align="right">8409</td>
<td align="right">6894607</td>
<td align="right">-6.709192</td>
</tr>
<tr class="even">
<td align="left">muy</td>
<td align="right">8354</td>
<td align="right">6894607</td>
<td align="right">-6.715754</td>
</tr>
<tr class="odd">
<td align="left">cuando</td>
<td align="right">8240</td>
<td align="right">6894607</td>
<td align="right">-6.729494</td>
</tr>
<tr class="even">
<td align="left">según</td>
<td align="right">8018</td>
<td align="right">6894607</td>
<td align="right">-6.756806</td>
</tr>
<tr class="odd">
<td align="left">son</td>
<td align="right">7992</td>
<td align="right">6894607</td>
<td align="right">-6.760054</td>
</tr>
<tr class="even">
<td align="left">porque</td>
<td align="right">7548</td>
<td align="right">6894607</td>
<td align="right">-6.817212</td>
</tr>
<tr class="odd">
<td align="left">gobierno</td>
<td align="right">7402</td>
<td align="right">6894607</td>
<td align="right">-6.836745</td>
</tr>
<tr class="even">
<td align="left">euros</td>
<td align="right">7310</td>
<td align="right">6894607</td>
<td align="right">-6.849252</td>
</tr>
<tr class="odd">
<td align="left">hay</td>
<td align="right">7274</td>
<td align="right">6894607</td>
<td align="right">-6.854188</td>
</tr>
<tr class="even">
<td align="left">ser</td>
<td align="right">7198</td>
<td align="right">6894607</td>
<td align="right">-6.864692</td>
</tr>
<tr class="odd">
<td align="left">parte</td>
<td align="right">6866</td>
<td align="right">6894607</td>
<td align="right">-6.911913</td>
</tr>
<tr class="even">
<td align="left">tiene</td>
<td align="right">6676</td>
<td align="right">6894607</td>
<td align="right">-6.939976</td>
</tr>
<tr class="odd">
<td align="left"><em>punto_coma</em></td>
<td align="right">6558</td>
<td align="right">6894607</td>
<td align="right">-6.957809</td>
</tr>
<tr class="even">
<td align="left">así</td>
<td align="right">6489</td>
<td align="right">6894607</td>
<td align="right">-6.968386</td>
</tr>
<tr class="odd">
<td align="left">todos</td>
<td align="right">6424</td>
<td align="right">6894607</td>
<td align="right">-6.978454</td>
</tr>
<tr class="even">
<td align="left">además</td>
<td align="right">6403</td>
<td align="right">6894607</td>
<td align="right">-6.981728</td>
</tr>
<tr class="odd">
<td align="left">tras</td>
<td align="right">6223</td>
<td align="right">6894607</td>
<td align="right">-7.010243</td>
</tr>
<tr class="even">
<td align="left">aunque</td>
<td align="right">6020</td>
<td align="right">6894607</td>
<td align="right">-7.043407</td>
</tr>
<tr class="odd">
<td align="left">tres</td>
<td align="right">5965</td>
<td align="right">6894607</td>
<td align="right">-7.052586</td>
</tr>
<tr class="even">
<td align="left">durante</td>
<td align="right">5872</td>
<td align="right">6894607</td>
<td align="right">-7.068300</td>
</tr>
<tr class="odd">
<td align="left">sido</td>
<td align="right">5845</td>
<td align="right">6894607</td>
<td align="right">-7.072908</td>
</tr>
<tr class="even">
<td align="left">me</td>
<td align="right">5823</td>
<td align="right">6894607</td>
<td align="right">-7.076679</td>
</tr>
<tr class="odd">
<td align="left">ayer</td>
<td align="right">5774</td>
<td align="right">6894607</td>
<td align="right">-7.085130</td>
</tr>
<tr class="even">
<td align="left">españa</td>
<td align="right">5725</td>
<td align="right">6894607</td>
<td align="right">-7.093652</td>
</tr>
<tr class="odd">
<td align="left">000</td>
<td align="right">5671</td>
<td align="right">6894607</td>
<td align="right">-7.103129</td>
</tr>
<tr class="even">
<td align="left">uno</td>
<td align="right">5532</td>
<td align="right">6894607</td>
<td align="right">-7.127945</td>
</tr>
<tr class="odd">
<td align="left">presidente</td>
<td align="right">5488</td>
<td align="right">6894607</td>
<td align="right">-7.135931</td>
</tr>
<tr class="even">
<td align="left">sólo</td>
<td align="right">5388</td>
<td align="right">6894607</td>
<td align="right">-7.154320</td>
</tr>
<tr class="odd">
<td align="left">día</td>
<td align="right">5372</td>
<td align="right">6894607</td>
<td align="right">-7.157294</td>
</tr>
<tr class="even">
<td align="left">ahora</td>
<td align="right">5353</td>
<td align="right">6894607</td>
<td align="right">-7.160838</td>
</tr>
<tr class="odd">
<td align="left">donde</td>
<td align="right">5344</td>
<td align="right">6894607</td>
<td align="right">-7.162520</td>
</tr>
<tr class="even">
<td align="left">pasado</td>
<td align="right">5318</td>
<td align="right">6894607</td>
<td align="right">-7.167397</td>
</tr>
<tr class="odd">
<td align="left">después</td>
<td align="right">5287</td>
<td align="right">6894607</td>
<td align="right">-7.173244</td>
</tr>
<tr class="even">
<td align="left">hace</td>
<td align="right">5206</td>
<td align="right">6894607</td>
<td align="right">-7.188683</td>
</tr>
<tr class="odd">
<td align="left">millones</td>
<td align="right">5188</td>
<td align="right">6894607</td>
<td align="right">-7.192146</td>
</tr>
<tr class="even">
<td align="left">partido</td>
<td align="right">5036</td>
<td align="right">6894607</td>
<td align="right">-7.221883</td>
</tr>
<tr class="odd">
<td align="left">otros</td>
<td align="right">4843</td>
<td align="right">6894607</td>
<td align="right">-7.260960</td>
</tr>
<tr class="even">
<td align="left">vez</td>
<td align="right">4787</td>
<td align="right">6894607</td>
<td align="right">-7.272591</td>
</tr>
<tr class="odd">
<td align="left">primera</td>
<td align="right">4778</td>
<td align="right">6894607</td>
<td align="right">-7.274473</td>
</tr>
<tr class="even">
<td align="left">ante</td>
<td align="right">4682</td>
<td align="right">6894607</td>
<td align="right">-7.294769</td>
</tr>
<tr class="odd">
<td align="left">hoy</td>
<td align="right">4663</td>
<td align="right">6894607</td>
<td align="right">-7.298836</td>
</tr>
<tr class="even">
<td align="left">contra</td>
<td align="right">4643</td>
<td align="right">6894607</td>
<td align="right">-7.303134</td>
</tr>
<tr class="odd">
<td align="left">había</td>
<td align="right">4602</td>
<td align="right">6894607</td>
<td align="right">-7.312004</td>
</tr>
<tr class="even">
<td align="left">puede</td>
<td align="right">4590</td>
<td align="right">6894607</td>
<td align="right">-7.314615</td>
</tr>
<tr class="odd">
<td align="left">cada</td>
<td align="right">4516</td>
<td align="right">6894607</td>
<td align="right">-7.330868</td>
</tr>
<tr class="even">
<td align="left">equipo</td>
<td align="right">4484</td>
<td align="right">6894607</td>
<td align="right">-7.337979</td>
</tr>
<tr class="odd">
<td align="left">personas</td>
<td align="right">4479</td>
<td align="right">6894607</td>
<td align="right">-7.339095</td>
</tr>
<tr class="even">
<td align="left">e</td>
<td align="right">4464</td>
<td align="right">6894607</td>
<td align="right">-7.342450</td>
</tr>
<tr class="odd">
<td align="left">gran</td>
<td align="right">4439</td>
<td align="right">6894607</td>
<td align="right">-7.348066</td>
</tr>
<tr class="even">
<td align="left">ni</td>
<td align="right">4418</td>
<td align="right">6894607</td>
<td align="right">-7.352808</td>
</tr>
<tr class="odd">
<td align="left">nos</td>
<td align="right">4363</td>
<td align="right">6894607</td>
<td align="right">-7.365335</td>
</tr>
<tr class="even">
<td align="left">antes</td>
<td align="right">4352</td>
<td align="right">6894607</td>
<td align="right">-7.367859</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb783-1" aria-hidden="true" tabindex="-1"></a>mod_bi <span class="sc">|&gt;</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(num)) <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="dv">100</span>) <span class="sc">|&gt;</span> knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">w_n_1</th>
<th align="left">w_n_0</th>
<th align="right">num</th>
<th align="right">denom</th>
<th align="right">log_p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left"><em>ss</em></td>
<td align="right">93073</td>
<td align="right">248139</td>
<td align="right">-0.9806049</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">la</td>
<td align="right">64367</td>
<td align="right">426481</td>
<td align="right">-1.8909667</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">el</td>
<td align="right">34475</td>
<td align="right">183614</td>
<td align="right">-1.6726013</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">la</td>
<td align="right">29086</td>
<td align="right">183614</td>
<td align="right">-1.8425788</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">los</td>
<td align="right">26980</td>
<td align="right">426481</td>
<td align="right">-2.7604720</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">que</td>
<td align="right">22964</td>
<td align="right">380344</td>
<td align="right">-2.8071483</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">la</td>
<td align="right">22943</td>
<td align="right">130347</td>
<td align="right">-1.7371872</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="left">se</td>
<td align="right">19073</td>
<td align="right">210647</td>
<td align="right">-2.4019100</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">el</td>
<td align="right">19019</td>
<td align="right">380344</td>
<td align="right">-2.9956376</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">las</td>
<td align="right">16151</td>
<td align="right">426481</td>
<td align="right">-3.2735859</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">el</td>
<td align="right">15308</td>
<td align="right">100000</td>
<td align="right">-1.8767946</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">y</td>
<td align="right">15277</td>
<td align="right">380344</td>
<td align="right">-3.2147277</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">en</td>
<td align="right">14330</td>
<td align="right">380344</td>
<td align="right">-3.2787209</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="left">el</td>
<td align="right">13521</td>
<td align="right">210647</td>
<td align="right">-2.7459397</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">la</td>
<td align="right">13421</td>
<td align="right">380344</td>
<td align="right">-3.3442555</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="left">el</td>
<td align="right">12165</td>
<td align="right">248139</td>
<td align="right">-3.0154261</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">los</td>
<td align="right">12116</td>
<td align="right">130347</td>
<td align="right">-2.3756732</td>
</tr>
<tr class="even">
<td align="left">lo</td>
<td align="left">que</td>
<td align="right">11115</td>
<td align="right">27222</td>
<td align="right">-0.8957299</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">la</td>
<td align="right">10394</td>
<td align="right">100000</td>
<td align="right">-2.2639415</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="left">la</td>
<td align="right">10203</td>
<td align="right">210647</td>
<td align="right">-3.0275020</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">pero</td>
<td align="right">9406</td>
<td align="right">380344</td>
<td align="right">-3.6997283</td>
</tr>
<tr class="even">
<td align="left">con</td>
<td align="left">el</td>
<td align="right">9033</td>
<td align="right">60358</td>
<td align="right">-1.8994090</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left">el</td>
<td align="right">9022</td>
<td align="right">158689</td>
<td align="right">-2.8672803</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">con</td>
<td align="right">8573</td>
<td align="right">380344</td>
<td align="right">-3.7924584</td>
</tr>
<tr class="odd">
<td align="left">por</td>
<td align="left">la</td>
<td align="right">8400</td>
<td align="right">62876</td>
<td align="right">-2.0129328</td>
</tr>
<tr class="even">
<td align="left">por</td>
<td align="left">el</td>
<td align="right">8387</td>
<td align="right">62876</td>
<td align="right">-2.0144816</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">la</td>
<td align="right">8349</td>
<td align="right">248139</td>
<td align="right">-3.3918473</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">los</td>
<td align="right">8314</td>
<td align="right">183614</td>
<td align="right">-3.0948949</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">en</td>
<td align="right">8114</td>
<td align="right">248139</td>
<td align="right">-3.4203981</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="left">no</td>
<td align="right">8111</td>
<td align="right">210647</td>
<td align="right">-3.2569626</td>
</tr>
<tr class="odd">
<td align="left">con</td>
<td align="left">la</td>
<td align="right">7989</td>
<td align="right">60358</td>
<td align="right">-2.0222279</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="left">la</td>
<td align="right">7970</td>
<td align="right">158689</td>
<td align="right">-2.9912618</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">que</td>
<td align="right">7956</td>
<td align="right">426481</td>
<td align="right">-3.9816415</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">de</td>
<td align="right">7696</td>
<td align="right">380344</td>
<td align="right">-3.9003754</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">las</td>
<td align="right">7561</td>
<td align="right">130347</td>
<td align="right">-2.8471967</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">se</td>
<td align="right">7363</td>
<td align="right">380344</td>
<td align="right">-3.9446086</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">en</td>
<td align="right">7271</td>
<td align="right">100000</td>
<td align="right">-2.6212764</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">un</td>
<td align="right">7268</td>
<td align="right">426481</td>
<td align="right">-4.0720867</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">a</td>
<td align="right">7076</td>
<td align="right">380344</td>
<td align="right">-3.9843673</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">un</td>
<td align="right">6681</td>
<td align="right">183614</td>
<td align="right">-3.3135681</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">ha</td>
<td align="right">6528</td>
<td align="right">380344</td>
<td align="right">-4.0649755</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">las</td>
<td align="right">6237</td>
<td align="right">183614</td>
<td align="right">-3.3823364</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">por</td>
<td align="right">6218</td>
<td align="right">380344</td>
<td align="right">-4.1136278</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">su</td>
<td align="right">6073</td>
<td align="right">426481</td>
<td align="right">-4.2517151</td>
</tr>
<tr class="odd">
<td align="left">se</td>
<td align="left">ha</td>
<td align="right">6037</td>
<td align="right">77632</td>
<td align="right">-2.5540725</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="left">que</td>
<td align="right">5964</td>
<td align="right">158689</td>
<td align="right">-3.2812049</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">000</td>
<td align="right">5671</td>
<td align="right">248139</td>
<td align="right">-3.7786236</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">los</td>
<td align="right">5604</td>
<td align="right">380344</td>
<td align="right">-4.2175955</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left">los</td>
<td align="right">5555</td>
<td align="right">210647</td>
<td align="right">-3.6354853</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">una</td>
<td align="right">5551</td>
<td align="right">426481</td>
<td align="right">-4.3415897</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">su</td>
<td align="right">5532</td>
<td align="right">183614</td>
<td align="right">-3.5022863</td>
</tr>
<tr class="even">
<td align="left">la</td>
<td align="left">que</td>
<td align="right">5432</td>
<td align="right">261913</td>
<td align="right">-3.8757050</td>
</tr>
<tr class="odd">
<td align="left">el</td>
<td align="left">que</td>
<td align="right">5285</td>
<td align="right">212825</td>
<td align="right">-3.6955976</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">como</td>
<td align="right">5281</td>
<td align="right">380344</td>
<td align="right">-4.2769606</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left">en</td>
<td align="right">5084</td>
<td align="right">210647</td>
<td align="right">-3.7240854</td>
</tr>
<tr class="even">
<td align="left">no</td>
<td align="left">se</td>
<td align="right">4974</td>
<td align="right">46051</td>
<td align="right">-2.2255251</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left"><em>coma</em></td>
<td align="right">4896</td>
<td align="right">210647</td>
<td align="right">-3.7617652</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">según</td>
<td align="right">4827</td>
<td align="right">380344</td>
<td align="right">-4.3668509</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left">de</td>
<td align="right">4796</td>
<td align="right">158689</td>
<td align="right">-3.4991641</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="left">y</td>
<td align="right">4447</td>
<td align="right">248139</td>
<td align="right">-4.0217594</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">su</td>
<td align="right">4350</td>
<td align="right">130347</td>
<td align="right">-3.4000243</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">no</td>
<td align="right">4341</td>
<td align="right">380344</td>
<td align="right">-4.4729714</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left">ha</td>
<td align="right">4336</td>
<td align="right">210647</td>
<td align="right">-3.8832315</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">una</td>
<td align="right">4263</td>
<td align="right">183614</td>
<td align="right">-3.7628626</td>
</tr>
<tr class="odd">
<td align="left">los</td>
<td align="left">que</td>
<td align="right">4256</td>
<td align="right">108758</td>
<td align="right">-3.2407955</td>
</tr>
<tr class="even">
<td align="left">para</td>
<td align="left">el</td>
<td align="right">4160</td>
<td align="right">48948</td>
<td align="right">-2.4652434</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">un</td>
<td align="right">4072</td>
<td align="right">380344</td>
<td align="right">-4.5369418</td>
</tr>
<tr class="even">
<td align="left">más</td>
<td align="left">de</td>
<td align="right">4060</td>
<td align="right">27140</td>
<td align="right">-1.8998257</td>
</tr>
<tr class="odd">
<td align="left">con</td>
<td align="left">un</td>
<td align="right">4056</td>
<td align="right">60358</td>
<td align="right">-2.7000962</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">aunque</td>
<td align="right">3931</td>
<td align="right">380344</td>
<td align="right">-4.5721823</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left">en</td>
<td align="right">3922</td>
<td align="right">158689</td>
<td align="right">-3.7003446</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="left">los</td>
<td align="right">3898</td>
<td align="right">248139</td>
<td align="right">-4.1535255</td>
</tr>
<tr class="odd">
<td align="left">millones</td>
<td align="left">de</td>
<td align="right">3866</td>
<td align="right">5188</td>
<td align="right">-0.2941279</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left">los</td>
<td align="right">3784</td>
<td align="right">100000</td>
<td align="right">-3.2743885</td>
</tr>
<tr class="odd">
<td align="left">para</td>
<td align="left">la</td>
<td align="right">3766</td>
<td align="right">48948</td>
<td align="right">-2.5647451</td>
</tr>
<tr class="even">
<td align="left">todos</td>
<td align="left">los</td>
<td align="right">3617</td>
<td align="right">6424</td>
<td align="right">-0.5743960</td>
</tr>
<tr class="odd">
<td align="left">uno</td>
<td align="left">de</td>
<td align="right">3593</td>
<td align="right">5532</td>
<td align="right">-0.4315619</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="left">no</td>
<td align="right">3562</td>
<td align="right">248139</td>
<td align="right">-4.2436669</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left"><em>punto</em></td>
<td align="right">3559</td>
<td align="right">248139</td>
<td align="right">-4.2445095</td>
</tr>
<tr class="even">
<td align="left">para</td>
<td align="left">que</td>
<td align="right">3535</td>
<td align="right">48948</td>
<td align="right">-2.6280452</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">al</td>
<td align="right">3524</td>
<td align="right">380344</td>
<td align="right">-4.6814794</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">lo</td>
<td align="right">3511</td>
<td align="right">380344</td>
<td align="right">-4.6851752</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">ya</td>
<td align="right">3499</td>
<td align="right">380344</td>
<td align="right">-4.6885989</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">un</td>
<td align="right">3480</td>
<td align="right">130347</td>
<td align="right">-3.6231678</td>
</tr>
<tr class="odd">
<td align="left">ha</td>
<td align="left">sido</td>
<td align="right">3430</td>
<td align="right">41228</td>
<td align="right">-2.4865574</td>
</tr>
<tr class="even">
<td align="left">es</td>
<td align="left">el</td>
<td align="right">3417</td>
<td align="right">35381</td>
<td align="right">-2.3374120</td>
</tr>
<tr class="odd">
<td align="left">ya</td>
<td align="left">que</td>
<td align="right">3379</td>
<td align="right">12056</td>
<td align="right">-1.2719827</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="left">los</td>
<td align="right">3363</td>
<td align="right">158689</td>
<td align="right">-3.8541129</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">este</td>
<td align="right">3310</td>
<td align="right">426481</td>
<td align="right">-4.8586196</td>
</tr>
<tr class="even">
<td align="left">es</td>
<td align="left">que</td>
<td align="right">3303</td>
<td align="right">35381</td>
<td align="right">-2.3713438</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">una</td>
<td align="right">3255</td>
<td align="right">380344</td>
<td align="right">-4.7608838</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">para</td>
<td align="right">3229</td>
<td align="right">380344</td>
<td align="right">-4.7689036</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">sus</td>
<td align="right">3219</td>
<td align="right">426481</td>
<td align="right">-4.8864971</td>
</tr>
<tr class="even">
<td align="left">además</td>
<td align="left"><em>coma</em></td>
<td align="right">3192</td>
<td align="right">6403</td>
<td align="right">-0.6961190</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">este</td>
<td align="right">3190</td>
<td align="right">183614</td>
<td align="right">-4.0528148</td>
</tr>
<tr class="even">
<td align="left">el</td>
<td align="left">presidente</td>
<td align="right">3136</td>
<td align="right">212825</td>
<td align="right">-4.2175221</td>
</tr>
<tr class="odd">
<td align="left">con</td>
<td align="left">los</td>
<td align="right">3134</td>
<td align="right">60358</td>
<td align="right">-2.9579834</td>
</tr>
<tr class="even">
<td align="left">después</td>
<td align="left">de</td>
<td align="right">3129</td>
<td align="right">5287</td>
<td align="right">-0.5245375</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left">a</td>
<td align="right">3092</td>
<td align="right">158689</td>
<td align="right">-3.9381282</td>
</tr>
<tr class="even">
<td align="left">se</td>
<td align="left">han</td>
<td align="right">3079</td>
<td align="right">77632</td>
<td align="right">-3.2273748</td>
</tr>
</tbody>
</table>
<p>¿Qué palabra es más probable que aparezca después de <em>en</em>,
la palabra <em>la</em> o la palabra <em>el</em>?</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb784-1" aria-hidden="true" tabindex="-1"></a>mod_tri <span class="sc">|&gt;</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(num)) <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="dv">100</span>) <span class="sc">|&gt;</span> knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">w_n_2</th>
<th align="left">w_n_1</th>
<th align="left">w_n_0</th>
<th align="right">num</th>
<th align="right">denom</th>
<th align="right">log_p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">el</td>
<td align="right">15308</td>
<td align="right">100000</td>
<td align="right">-1.8767946</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">la</td>
<td align="right">10394</td>
<td align="right">100000</td>
<td align="right">-2.2639415</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">en</td>
<td align="right">7271</td>
<td align="right">100000</td>
<td align="right">-2.6212764</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">los</td>
<td align="right">3784</td>
<td align="right">100000</td>
<td align="right">-3.2743885</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">por</td>
<td align="right">2915</td>
<td align="right">100000</td>
<td align="right">-3.5353004</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">el</td>
<td align="left">que</td>
<td align="right">2846</td>
<td align="right">34475</td>
<td align="right">-2.4943199</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">en</td>
<td align="left">el</td>
<td align="right">2724</td>
<td align="right">14330</td>
<td align="right">-1.6602539</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">ya</td>
<td align="left">que</td>
<td align="right">2619</td>
<td align="right">3499</td>
<td align="right">-0.2896846</td>
</tr>
<tr class="odd">
<td align="left">uno</td>
<td align="left">de</td>
<td align="left">los</td>
<td align="right">2616</td>
<td align="right">3593</td>
<td align="right">-0.3173411</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">lo</td>
<td align="left">que</td>
<td align="right">2430</td>
<td align="right">3511</td>
<td align="right">-0.3680096</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">la</td>
<td align="left">que</td>
<td align="right">2426</td>
<td align="right">29086</td>
<td align="right">-2.4840131</td>
</tr>
<tr class="even">
<td align="left">millones</td>
<td align="left">de</td>
<td align="left">euros</td>
<td align="right">2373</td>
<td align="right">3866</td>
<td align="right">-0.4880654</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">en</td>
<td align="left">la</td>
<td align="right">2283</td>
<td align="right">14330</td>
<td align="right">-1.8368649</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">que</td>
<td align="left">se</td>
<td align="right">2217</td>
<td align="right">22964</td>
<td align="right">-2.3377728</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">las</td>
<td align="right">1949</td>
<td align="right">100000</td>
<td align="right">-3.9378538</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">a</td>
<td align="right">1883</td>
<td align="right">100000</td>
<td align="right">-3.9723039</td>
</tr>
<tr class="odd">
<td align="left">sin</td>
<td align="left">embargo</td>
<td align="left"><em>coma</em></td>
<td align="right">1873</td>
<td align="right">2062</td>
<td align="right">-0.0961350</td>
</tr>
<tr class="even">
<td align="left">por</td>
<td align="left">lo</td>
<td align="left">que</td>
<td align="right">1862</td>
<td align="right">2350</td>
<td align="right">-0.2327641</td>
</tr>
<tr class="odd">
<td align="left">una</td>
<td align="left">de</td>
<td align="left">las</td>
<td align="right">1759</td>
<td align="right">2423</td>
<td align="right">-0.3202610</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">mientras</td>
<td align="left">que</td>
<td align="right">1661</td>
<td align="right">2155</td>
<td align="right">-0.2603709</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">por</td>
<td align="left">lo</td>
<td align="right">1626</td>
<td align="right">6218</td>
<td align="right">-1.3413253</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">través</td>
<td align="left">de</td>
<td align="right">1584</td>
<td align="right">1958</td>
<td align="right">-0.2119703</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">000</td>
<td align="left">euros</td>
<td align="right">1574</td>
<td align="right">5671</td>
<td align="right">-1.2817453</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">no</td>
<td align="right">1568</td>
<td align="right">100000</td>
<td align="right">-4.1553693</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">además</td>
<td align="left"><em>coma</em></td>
<td align="right">1482</td>
<td align="right">1867</td>
<td align="right">-0.2309403</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">según</td>
<td align="right">1475</td>
<td align="right">100000</td>
<td align="right">-4.2165122</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">así</td>
<td align="left">como</td>
<td align="right">1404</td>
<td align="right">1721</td>
<td align="right">-0.2035802</td>
</tr>
<tr class="even">
<td align="left">presidente</td>
<td align="left">de</td>
<td align="left">la</td>
<td align="right">1381</td>
<td align="right">2186</td>
<td align="right">-0.4592655</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">partir</td>
<td align="left">de</td>
<td align="right">1361</td>
<td align="right">1738</td>
<td align="right">-0.2445153</td>
</tr>
<tr class="even">
<td align="left">el</td>
<td align="left">presidente</td>
<td align="left">de</td>
<td align="right">1331</td>
<td align="right">3136</td>
<td align="right">-0.8570176</td>
</tr>
<tr class="odd">
<td align="left">por</td>
<td align="left">su</td>
<td align="left">parte</td>
<td align="right">1323</td>
<td align="right">2893</td>
<td align="right">-0.7823921</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">de</td>
<td align="right">1305</td>
<td align="right">100000</td>
<td align="right">-4.3389671</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left">no</td>
<td align="left">se</td>
<td align="right">1284</td>
<td align="right">8111</td>
<td align="right">-1.8432410</td>
</tr>
<tr class="even">
<td align="left"><em>punto</em></td>
<td align="left">en</td>
<td align="left">el</td>
<td align="right">1271</td>
<td align="right">8114</td>
<td align="right">-1.8537870</td>
</tr>
<tr class="odd">
<td align="left">se</td>
<td align="left">trata</td>
<td align="left">de</td>
<td align="right">1252</td>
<td align="right">1533</td>
<td align="right">-0.2024843</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">además</td>
<td align="right">1240</td>
<td align="right">100000</td>
<td align="right">-4.3900588</td>
</tr>
<tr class="odd">
<td align="left">su</td>
<td align="left">parte</td>
<td align="left"><em>coma</em></td>
<td align="right">1237</td>
<td align="right">1388</td>
<td align="right">-0.1151748</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">pesar</td>
<td align="left">de</td>
<td align="right">1222</td>
<td align="right">1322</td>
<td align="right">-0.0786569</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">en</td>
<td align="left">el</td>
<td align="right">1212</td>
<td align="right">7271</td>
<td align="right">-1.7916219</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">para</td>
<td align="right">1206</td>
<td align="right">100000</td>
<td align="right">-4.4178611</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">y</td>
<td align="left">el</td>
<td align="right">1204</td>
<td align="right">15277</td>
<td align="right">-2.5406991</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">la</td>
<td align="left">ciudad</td>
<td align="right">1197</td>
<td align="right">64367</td>
<td align="right">-3.9847827</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">que</td>
<td align="left">el</td>
<td align="right">1184</td>
<td align="right">7956</td>
<td align="right">-1.9050278</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">a</td>
<td align="left">la</td>
<td align="right">1119</td>
<td align="right">7076</td>
<td align="right">-1.8442733</td>
</tr>
<tr class="odd">
<td align="left">que</td>
<td align="left">se</td>
<td align="left">ha</td>
<td align="right">1106</td>
<td align="right">19073</td>
<td align="right">-2.8475238</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">los</td>
<td align="left">últimos</td>
<td align="right">1104</td>
<td align="right">8314</td>
<td align="right">-2.0190009</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">y</td>
<td align="left">que</td>
<td align="right">1069</td>
<td align="right">15277</td>
<td align="right">-2.6596248</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">con</td>
<td align="left">el</td>
<td align="right">1068</td>
<td align="right">8573</td>
<td align="right">-2.0828300</td>
</tr>
<tr class="odd">
<td align="left"><em>coma</em></td>
<td align="left">que</td>
<td align="left">ha</td>
<td align="right">1032</td>
<td align="right">22964</td>
<td align="right">-3.1024291</td>
</tr>
<tr class="even">
<td align="left">la</td>
<td align="left">que</td>
<td align="left">se</td>
<td align="right">1032</td>
<td align="right">5432</td>
<td align="right">-1.6608087</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">con</td>
<td align="right">1016</td>
<td align="right">100000</td>
<td align="right">-4.5892968</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">además</td>
<td align="left">de</td>
<td align="right">986</td>
<td align="right">1822</td>
<td align="right">-0.6140337</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">en</td>
<td align="left">la</td>
<td align="right">979</td>
<td align="right">7271</td>
<td align="right">-2.0051175</td>
</tr>
<tr class="even">
<td align="left">el</td>
<td align="left">que</td>
<td align="left">se</td>
<td align="right">962</td>
<td align="right">5285</td>
<td align="right">-1.7036134</td>
</tr>
<tr class="odd">
<td align="left">el</td>
<td align="left">caso</td>
<td align="left">de</td>
<td align="right">961</td>
<td align="right">1655</td>
<td align="right">-0.5435819</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">con</td>
<td align="left">un</td>
<td align="right">950</td>
<td align="right">8573</td>
<td align="right">-2.1999110</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">y</td>
<td align="right">950</td>
<td align="right">100000</td>
<td align="right">-4.6564635</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">pero</td>
<td align="left">no</td>
<td align="right">948</td>
<td align="right">9406</td>
<td align="right">-2.2947486</td>
</tr>
<tr class="odd">
<td align="left">la</td>
<td align="left">guardia</td>
<td align="left">civil</td>
<td align="right">938</td>
<td align="right">1027</td>
<td align="right">-0.0906473</td>
</tr>
<tr class="even">
<td align="left">de</td>
<td align="left">lo</td>
<td align="left">que</td>
<td align="right">936</td>
<td align="right">1979</td>
<td align="right">-0.7487315</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">sin</td>
<td align="left">embargo</td>
<td align="right">933</td>
<td align="right">1216</td>
<td align="right">-0.2649169</td>
</tr>
<tr class="even">
<td align="left">lo</td>
<td align="left">que</td>
<td align="left">se</td>
<td align="right">923</td>
<td align="right">11115</td>
<td align="right">-2.4884216</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">además</td>
<td align="left"><em>coma</em></td>
<td align="right">919</td>
<td align="right">1240</td>
<td align="right">-0.2995805</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">sobre</td>
<td align="left">todo</td>
<td align="right">912</td>
<td align="right">1266</td>
<td align="right">-0.3279776</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">el</td>
<td align="left">caso</td>
<td align="right">905</td>
<td align="right">34475</td>
<td align="right">-3.6400548</td>
</tr>
<tr class="even">
<td align="left">que</td>
<td align="left">en</td>
<td align="left">el</td>
<td align="right">902</td>
<td align="right">5084</td>
<td align="right">-1.7292391</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">un</td>
<td align="right">901</td>
<td align="right">100000</td>
<td align="right">-4.7094202</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">pero</td>
<td align="right">898</td>
<td align="right">100000</td>
<td align="right">-4.7127554</td>
</tr>
<tr class="odd">
<td align="left">no</td>
<td align="left">obstante</td>
<td align="left"><em>coma</em></td>
<td align="right">896</td>
<td align="right">948</td>
<td align="right">-0.0564141</td>
</tr>
<tr class="even">
<td align="left">euros</td>
<td align="left"><em>punto</em></td>
<td align="left"><em>ss</em></td>
<td align="right">881</td>
<td align="right">1632</td>
<td align="right">-0.6165039</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">la</td>
<td align="left">que</td>
<td align="right">878</td>
<td align="right">22943</td>
<td align="right">-3.2631216</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">que</td>
<td align="left">no</td>
<td align="right">877</td>
<td align="right">22964</td>
<td align="right">-3.2651761</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">en</td>
<td align="left">la</td>
<td align="right">866</td>
<td align="right">8114</td>
<td align="right">-2.2374613</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">con</td>
<td align="left">la</td>
<td align="right">860</td>
<td align="right">8573</td>
<td align="right">-2.2994406</td>
</tr>
<tr class="odd">
<td align="left">el</td>
<td align="left">número</td>
<td align="left">de</td>
<td align="right">856</td>
<td align="right">1229</td>
<td align="right">-0.3616857</td>
</tr>
<tr class="even">
<td align="left">en</td>
<td align="left">este</td>
<td align="left">sentido</td>
<td align="right">854</td>
<td align="right">3190</td>
<td align="right">-1.3178450</td>
</tr>
<tr class="odd">
<td align="left">a</td>
<td align="left">lo</td>
<td align="left">largo</td>
<td align="right">853</td>
<td align="right">1569</td>
<td align="right">-0.6094342</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">de</td>
<td align="left">la</td>
<td align="right">839</td>
<td align="right">7696</td>
<td align="right">-2.2162453</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">así</td>
<td align="right">836</td>
<td align="right">100000</td>
<td align="right">-4.7842969</td>
</tr>
<tr class="even">
<td align="left">después</td>
<td align="left">de</td>
<td align="left">que</td>
<td align="right">836</td>
<td align="right">3129</td>
<td align="right">-1.3198401</td>
</tr>
<tr class="odd">
<td align="left">de</td>
<td align="left">que</td>
<td align="left">la</td>
<td align="right">828</td>
<td align="right">7956</td>
<td align="right">-2.2626685</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="left">de</td>
<td align="left">la</td>
<td align="right">822</td>
<td align="right">4796</td>
<td align="right">-1.7637971</td>
</tr>
<tr class="odd">
<td align="left">castilla</td>
<td align="left">y</td>
<td align="left">león</td>
<td align="right">817</td>
<td align="right">833</td>
<td align="right">-0.0193945</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">una</td>
<td align="right">812</td>
<td align="right">100000</td>
<td align="right">-4.8134251</td>
</tr>
<tr class="odd">
<td align="left">en</td>
<td align="left">los</td>
<td align="left">que</td>
<td align="right">810</td>
<td align="right">8314</td>
<td align="right">-2.3286619</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">tras</td>
<td align="right">807</td>
<td align="right">100000</td>
<td align="right">-4.8196018</td>
</tr>
<tr class="odd">
<td align="left">la</td>
<td align="left">posibilidad</td>
<td align="left">de</td>
<td align="right">801</td>
<td align="right">858</td>
<td align="right">-0.0687432</td>
</tr>
<tr class="even">
<td align="left">un</td>
<td align="left">total</td>
<td align="left">de</td>
<td align="right">800</td>
<td align="right">823</td>
<td align="right">-0.0283445</td>
</tr>
<tr class="odd">
<td align="left">por</td>
<td align="left">parte</td>
<td align="left">de</td>
<td align="right">797</td>
<td align="right">1139</td>
<td align="right">-0.3570513</td>
</tr>
<tr class="even">
<td align="left">el</td>
<td align="left">presidente</td>
<td align="left">del</td>
<td align="right">792</td>
<td align="right">3136</td>
<td align="right">-1.3761420</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">al</td>
<td align="right">788</td>
<td align="right">100000</td>
<td align="right">-4.8434274</td>
</tr>
<tr class="even">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">es</td>
<td align="right">785</td>
<td align="right">100000</td>
<td align="right">-4.8472417</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left">por</td>
<td align="left">su</td>
<td align="right">781</td>
<td align="right">2915</td>
<td align="right">-1.3170499</td>
</tr>
<tr class="even">
<td align="left"><em>coma</em></td>
<td align="left">y</td>
<td align="left">la</td>
<td align="right">775</td>
<td align="right">15277</td>
<td align="right">-2.9812407</td>
</tr>
<tr class="odd">
<td align="left"><em>punto</em></td>
<td align="left">00</td>
<td align="left">horas</td>
<td align="right">769</td>
<td align="right">1182</td>
<td align="right">-0.4298722</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="left">en</td>
<td align="left">el</td>
<td align="right">767</td>
<td align="right">3922</td>
<td align="right">-1.6318702</td>
</tr>
<tr class="odd">
<td align="left">parte</td>
<td align="left">de</td>
<td align="left">la</td>
<td align="right">762</td>
<td align="right">2513</td>
<td align="right">-1.1932860</td>
</tr>
<tr class="even">
<td align="left">a</td>
<td align="left">los</td>
<td align="left">que</td>
<td align="right">741</td>
<td align="right">12116</td>
<td align="right">-2.7942815</td>
</tr>
<tr class="odd">
<td align="left"><em>s</em></td>
<td align="left"><em>s</em></td>
<td align="left">también</td>
<td align="right">738</td>
<td align="right">100000</td>
<td align="right">-4.9089816</td>
</tr>
<tr class="even">
<td align="left">el</td>
<td align="left">resto</td>
<td align="left">de</td>
<td align="right">736</td>
<td align="right">1279</td>
<td align="right">-0.5526037</td>
</tr>
</tbody>
</table>
<div id="problema-de-los-ceros" class="section level3 unnumbered">
<h3>Problema de los ceros</h3>
<p>Podemos ahora evaluar la probabilidad de ocurrencia de
textos utilizando las frecuencias que calculamos arriba:</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-1" aria-hidden="true" tabindex="-1"></a>n_gramas <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">unigramas =</span> mod_uni,</span>
<span id="cb785-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bigramas  =</span> mod_bi,</span>
<span id="cb785-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">trigramas =</span> mod_tri)</span>
<span id="cb785-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb785-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-5" aria-hidden="true" tabindex="-1"></a>log_prob <span class="ot">&lt;-</span> <span class="cf">function</span>(textos, n_gramas, <span class="at">n =</span> <span class="dv">2</span>, <span class="at">laplace =</span> <span class="cn">FALSE</span>, <span class="at">delta =</span> <span class="fl">0.001</span>, <span class="at">vocab_env =</span> <span class="cn">NULL</span>){</span>
<span id="cb785-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-6" aria-hidden="true" tabindex="-1"></a>  df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(textos), <span class="at">txt =</span> textos) <span class="sc">|&gt;</span></span>
<span id="cb785-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-7" aria-hidden="true" tabindex="-1"></a>         <span class="fu">mutate</span>(<span class="at">txt =</span> <span class="fu">normalizar</span>(txt)) </span>
<span id="cb785-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(vocab_env)){</span>
<span id="cb785-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-9" aria-hidden="true" tabindex="-1"></a>    df <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">txt_u =</span> <span class="fu">map_chr</span>(txt, <span class="sc">~</span><span class="fu">restringir_vocab</span>(.x, <span class="at">vocab =</span> vocab_env))) <span class="sc">|&gt;</span> </span>
<span id="cb785-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(id, txt_u) <span class="sc">|&gt;</span> <span class="fu">rename</span>(<span class="at">txt =</span> txt_u)</span>
<span id="cb785-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb785-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-12" aria-hidden="true" tabindex="-1"></a>  token_nom <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&#39;w_n_&#39;</span>, <span class="fu">rev</span>(<span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span>n)) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb785-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-13" aria-hidden="true" tabindex="-1"></a>  df_tokens <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> <span class="fu">group_by</span>(id) <span class="sc">|&gt;</span></span>
<span id="cb785-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-14" aria-hidden="true" tabindex="-1"></a>                <span class="fu">unnest_tokens</span>(ngrama, txt, </span>
<span id="cb785-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="at">n =</span> n) <span class="sc">|&gt;</span></span>
<span id="cb785-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-16" aria-hidden="true" tabindex="-1"></a>                <span class="fu">separate</span>(ngrama, token_nom, <span class="st">&quot; &quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb785-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-17" aria-hidden="true" tabindex="-1"></a>                <span class="fu">left_join</span>(n_gramas[[n]], <span class="at">by =</span> token_nom)</span>
<span id="cb785-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(laplace){</span>
<span id="cb785-19"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-19" aria-hidden="true" tabindex="-1"></a>    V <span class="ot">&lt;-</span> <span class="fu">nrow</span>(n_gramas[[<span class="dv">1</span>]])</span>
<span id="cb785-20"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-20" aria-hidden="true" tabindex="-1"></a>    log_probs <span class="ot">&lt;-</span> <span class="fu">log</span>(df_tokens[[<span class="st">&quot;num&quot;</span>]] <span class="sc">+</span> delta) <span class="sc">-</span> <span class="fu">log</span>(df_tokens[[<span class="st">&quot;denom&quot;</span>]] <span class="sc">+</span> delta<span class="sc">*</span>V )</span>
<span id="cb785-21"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-21" aria-hidden="true" tabindex="-1"></a>    log_probs[<span class="fu">is.na</span>(log_probs)] <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span><span class="sc">/</span>V)</span>
<span id="cb785-22"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-22" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb785-23"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-23" aria-hidden="true" tabindex="-1"></a>    log_probs <span class="ot">&lt;-</span> df_tokens[[<span class="st">&quot;log_p&quot;</span>]]</span>
<span id="cb785-24"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-24" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb785-25"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-25" aria-hidden="true" tabindex="-1"></a>  log_probs <span class="ot">&lt;-</span> <span class="fu">split</span>(log_probs, df_tokens<span class="sc">$</span>id)</span>
<span id="cb785-26"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(log_probs, mean)</span>
<span id="cb785-27"><a href="modelos-de-lenguaje-y-n-gramas.html#cb785-27" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb786-1" aria-hidden="true" tabindex="-1"></a>textos <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;un día muy soleado&quot;</span>,</span>
<span id="cb786-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb786-2" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;este de es ejemplo un&quot;</span>,</span>
<span id="cb786-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb786-3" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;este es un ejemplo de&quot;</span>,</span>
<span id="cb786-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb786-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;esta frase es exotiquísima&quot;</span>)</span>
<span id="cb786-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb786-5" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas, <span class="at">n =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##         1         2         3         4 
## -7.988631 -5.458781 -5.458781        NA</code></pre>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb788-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas, <span class="at">n =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##         1         2         3         4 
##        NA -7.824663 -3.722903        NA</code></pre>
<div class="sourceCode" id="cb790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb790-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb790-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas, <span class="at">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##         1         2         3         4 
##        NA        NA -2.177098        NA</code></pre>
<p><strong>Observaciones</strong>:</p>
<ul>
<li>El modelo de unigramas claramente no captura estructura en el orden de palabras. La segunda frase por ejemplo,
tiene probabilidad alta porque tiene tokens o palabras comunes, pero la frase en realidad tendría probabilidad muy
baja de ocurrir en el lenguaje. Esto parece incorrecto.</li>
<li>La cuarta frase tiene probabilidad 0 en todos los modelos porque la palabra <em>exotiquísima</em> no existe en el vocabulario de entrenamiento. Esto parece incorrecto.</li>
<li>La primera frase tiene probabilidad 0 en el modelo de bigramas y trigramas, porque nunca encontró alguna serie de tres palabras juntas. Esto parece incorrecto.</li>
</ul>
<p>Incluso el modelo de bigramas puede dar probabilidad cero a frase que deberían ser relativamente comunes,
pues el conjunto de frases es muy grande:</p>
<div class="sourceCode" id="cb792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb792-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb792-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-2" aria-hidden="true" tabindex="-1"></a>textos <span class="ot">&lt;-</span> <span class="st">&quot;Otro día muy soleado&quot;</span></span>
<span id="cb792-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(textos), <span class="at">txt =</span> textos) <span class="sc">|&gt;</span></span>
<span id="cb792-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-4" aria-hidden="true" tabindex="-1"></a>         <span class="fu">mutate</span>(<span class="at">txt =</span> <span class="fu">normalizar</span>(txt))</span>
<span id="cb792-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-5" aria-hidden="true" tabindex="-1"></a>token_nom <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&#39;w_n_&#39;</span>, <span class="fu">rev</span>(<span class="fu">seq</span>(<span class="dv">1</span><span class="sc">:</span>n)) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb792-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-6" aria-hidden="true" tabindex="-1"></a>df_tokens <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span> <span class="fu">group_by</span>(id) <span class="sc">|&gt;</span></span>
<span id="cb792-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-7" aria-hidden="true" tabindex="-1"></a>                <span class="fu">unnest_tokens</span>(ngrama, txt, </span>
<span id="cb792-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="at">n =</span> n) <span class="sc">|&gt;</span></span>
<span id="cb792-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-9" aria-hidden="true" tabindex="-1"></a>                <span class="fu">separate</span>(ngrama, token_nom, <span class="st">&quot; &quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb792-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-10" aria-hidden="true" tabindex="-1"></a>                <span class="fu">left_join</span>(n_gramas[[n]], <span class="at">by =</span> token_nom)</span>
<span id="cb792-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb792-11" aria-hidden="true" tabindex="-1"></a>df_tokens</span></code></pre></div>
<pre><code>## # A tibble: 3 × 6
## # Groups:   id [1]
##      id w_n_1 w_n_0     num denom log_p
##   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1     1 otro  día        53  3995 -4.32
## 2     1 día   muy        15  5372 -5.88
## 3     1 muy   soleado    NA    NA NA</code></pre>
<p>El problema es que no observamos “muy soleado,” y esta frase tendría 0 probabilidad de ocurrir.</p>
<hr />
<p>Esta última observación es importante: cuando no encontramos en nuestros conteos
un bigrama (o trigrama, etc.) dado, la probabilidad asignada es 0.</p>
<p>Aunque para algunas frases esta asignación es correcta (una sucesión de palabras que casi no puede
ocurrir en el lenguaje), muchas veces esto se debe a que los datos son ralos: la mayor
parte de las frases posibles no son observadas en nuestro corpus, y es erróneo
asignarles probabilidad 0. Más en general, cuando los conteos de bigramas son
chicos, sabemos que nuestra estimación por máxima verosimilitud tendrá varianza
alta.</p>
<p>Estos ceros ocurren de dos maneras:</p>
<ul>
<li>Algunas palabras son <em>nuevas</em>: no las observamos en nuestros
datos de entrenamiento.</li>
<li>No observamos bigramas, trigramas, etc. específicos (por ejemplo,
observamos <em>día</em>, y <em>aburrido</em> pero no observamos <em>día aburrido</em>).</li>
</ul>
<div id="palabras-desconocidas" class="section level4 unnumbered">
<h4>Palabras desconocidas</h4>
<p>Para el primer problema, podemos entrenar nuestro modelo
con una palabra adicional <span class="math inline">\(&lt;unk&gt;\)</span>, que denota palabras desconocidas. Una
estrategia es tomar las palabras con frecuencia baja y sustituirlas por
<unk>, por ejemplo:</p>
<div class="sourceCode" id="cb794"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb794-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-1" aria-hidden="true" tabindex="-1"></a>vocabulario_txt <span class="ot">&lt;-</span> n_gramas[[<span class="dv">1</span>]] <span class="sc">|&gt;</span> <span class="fu">filter</span>(num <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">|&gt;</span> </span>
<span id="cb794-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(w_n_0)</span>
<span id="cb794-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-3" aria-hidden="true" tabindex="-1"></a>vocab_env <span class="ot">&lt;-</span> <span class="fu">new.env</span>()</span>
<span id="cb794-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-4" aria-hidden="true" tabindex="-1"></a>vocab_env[[<span class="st">&quot;_unk_&quot;</span>]] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb794-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(a <span class="cf">in</span> vocabulario_txt){</span>
<span id="cb794-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-6" aria-hidden="true" tabindex="-1"></a>    vocab_env[[a]] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb794-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb794-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb794-8" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(n_gramas[[<span class="dv">1</span>]])</span></code></pre></div>
<pre><code>## [1] 137263</code></pre>
<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb796-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb796-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(n_gramas[[<span class="dv">1</span>]]<span class="sc">$</span>num)</span></code></pre></div>
<pre><code>## [1] 6894607</code></pre>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb798-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(vocab_env)</span></code></pre></div>
<pre><code>## [1] 77933</code></pre>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-1" aria-hidden="true" tabindex="-1"></a>restringir_vocab <span class="ot">&lt;-</span> <span class="cf">function</span>(texto, vocab_env){</span>
<span id="cb800-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-2" aria-hidden="true" tabindex="-1"></a>  texto_v <span class="ot">&lt;-</span> <span class="fu">strsplit</span>(texto, <span class="st">&quot; &quot;</span>)[[<span class="dv">1</span>]]</span>
<span id="cb800-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-3" aria-hidden="true" tabindex="-1"></a>  texto_v <span class="ot">&lt;-</span> <span class="fu">lapply</span>(texto_v, <span class="cf">function</span>(x){</span>
<span id="cb800-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(x <span class="sc">!=</span> <span class="st">&quot;&quot;</span>){</span>
<span id="cb800-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-5" aria-hidden="true" tabindex="-1"></a>        en_vocab <span class="ot">&lt;-</span> vocab_env[[x]]</span>
<span id="cb800-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="fu">is.null</span>(en_vocab)){</span>
<span id="cb800-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-7" aria-hidden="true" tabindex="-1"></a>            x <span class="ot">&lt;-</span> <span class="st">&quot;_unk_&quot;</span></span>
<span id="cb800-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-8" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb800-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-9" aria-hidden="true" tabindex="-1"></a>        x</span>
<span id="cb800-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb800-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-11" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb800-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-12" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">paste</span>(texto_v, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span>
<span id="cb800-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-13" aria-hidden="true" tabindex="-1"></a>  texto</span>
<span id="cb800-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb800-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-15" aria-hidden="true" tabindex="-1"></a>periodico_m_unk <span class="ot">&lt;-</span> periodico_m <span class="sc">|&gt;</span> </span>
<span id="cb800-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">txt_u =</span> <span class="fu">map_chr</span>(txt, <span class="sc">~</span><span class="fu">restringir_vocab</span>(.x, <span class="at">vocab_env =</span> vocab_env))) <span class="sc">|&gt;</span> </span>
<span id="cb800-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb800-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(id, txt_u) <span class="sc">|&gt;</span> <span class="fu">rename</span>(<span class="at">txt =</span> txt_u)</span></code></pre></div>
<p>Y ahora podemos reentrenar nuestros modelos:</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb801-1" aria-hidden="true" tabindex="-1"></a>mod_uni <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m_unk, <span class="at">n =</span> <span class="dv">1</span>)</span>
<span id="cb801-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb801-2" aria-hidden="true" tabindex="-1"></a>mod_bi  <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m_unk, <span class="at">n =</span> <span class="dv">2</span>)</span>
<span id="cb801-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb801-3" aria-hidden="true" tabindex="-1"></a>mod_tri <span class="ot">&lt;-</span> <span class="fu">conteo_ngramas</span>(periodico_m_unk, <span class="at">n =</span> <span class="dv">3</span>)</span>
<span id="cb801-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb801-4" aria-hidden="true" tabindex="-1"></a>n_gramas_u <span class="ot">&lt;-</span> <span class="fu">list</span>(mod_uni, mod_bi, mod_tri)</span></code></pre></div>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb802-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb802-1" aria-hidden="true" tabindex="-1"></a>textos <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;un día muy soleado&quot;</span>,</span>
<span id="cb802-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb802-2" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;este de es ejemplo un&quot;</span>,</span>
<span id="cb802-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb802-3" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;este es un ejemplo de&quot;</span>,</span>
<span id="cb802-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb802-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;esta frase es exotiquísima&quot;</span>)</span>
<span id="cb802-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb802-5" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">vocab_env =</span> vocab_env)</span></code></pre></div>
<pre><code>##         1         2         3         4 
## -8.005118 -5.470732 -5.470732 -6.447402</code></pre>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb804-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">2</span>, <span class="at">vocab_env =</span> vocab_env)</span></code></pre></div>
<pre><code>##         1         2         3         4 
##        NA -7.887497 -3.756993 -4.468375</code></pre>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb806-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">3</span>, <span class="at">vocab_env =</span> vocab_env)</span></code></pre></div>
<pre><code>##         1         2         3         4 
##        NA        NA -2.232099        NA</code></pre>
<p>Y con esto podemos resolver el problema de vocabulario desconocido.</p>
</div>
<div id="contexto-no-observado" class="section level4 unnumbered">
<h4>Contexto no observado</h4>
<p>Para el segundo problema, existen <strong>técnicas de suavizamiento</strong> (que veremos más adelante). El método más simple es el <strong>suavizamiento de Laplace</strong>,
en el que simplemente agregamos una cantidad <span class="math inline">\(\delta\)</span> a los conteos de unigramas, bigramas, etc.</p>
<p>Para unigramas, agregamos <span class="math inline">\(\delta\)</span> a cada posible unigrama. Si el tamaño del vocabulario
es <span class="math inline">\(V\)</span>, y el conteo total de <em>tokens</em> es <span class="math inline">\(N\)</span>, el nuevo conteo de <em>tokens</em> será entonces
<span class="math inline">\(N+\delta V\)</span>. Por ejemplo, la probabilidad para bigramas es:</p>
<p><span class="math display">\[P(w|a) = \frac{N(aw)}{N(a)} = \frac{N(aw)}{\sum_{z\in V} N(az)},\]</span>
De modo que la estimación suavizada (sumando <span class="math inline">\(\delta\)</span> a cada bigrama) es
<span class="math display">\[P_{L}(w|a) = \frac{N(aw)+\delta}{\sum_{z\in V} N(az)+\delta}= \frac{N(aw) + \delta}{N(z)+ \delta V} \]</span>
Para trigramas,
<span class="math display">\[P_{L}(w|ab) = \frac{N(abw)+\delta}{\sum_{z\in V} N(abz)+\delta}= \frac{N(abw) + \delta}{N(ab)+ \delta V} \]</span>
y así sucesivamente.</p>
<p><strong>Observación</strong>: este método es útil para introducir la idea de
suavizamiento, pero existen otros mejores que veremos más adelante
(ver sección 4.5 de <span class="citation">(<a href="#ref-jurafsky" role="doc-biblioref">Jurafsky and Martin 2000</a>)</span>, o 3.5 en la edición más reciente). Veremos más adelante también cómo
escoger hiperparámetros como <span class="math inline">\(\delta\)</span>.</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb808-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">laplace =</span> <span class="cn">TRUE</span>, <span class="at">delta =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>##         1         2         3         4 
## -8.004979 -5.470842 -5.470842 -8.337738</code></pre>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb810-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">2</span>, <span class="at">laplace =</span> <span class="cn">TRUE</span>, <span class="at">delta =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>##         1         2         3         4 
## -7.337730 -8.021005 -3.894912 -7.558278</code></pre>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb812-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log_prob</span>(textos, n_gramas_u, <span class="at">n =</span> <span class="dv">3</span>, <span class="at">laplace =</span> <span class="cn">TRUE</span>, <span class="at">delta =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<pre><code>##          1          2          3          4 
##  -7.907155 -11.252417  -3.477082 -11.252417</code></pre>
<p>Nótese que este suavizamiento cambia considerablemente las probabilides estimadas,
incluyendo algunas de ellas con conteos altos (esta técnica dispersa demasiada
probabilidad sobre conteos bajos).</p>
</div>
</div>
</div>
<div id="evaluación-de-modelos" class="section level2" number="9.6">
<h2><span class="header-section-number">9.6</span> Evaluación de modelos</h2>
<div id="generación-de-texto" class="section level3" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Generación de texto</h3>
<p>Una primera idea de qué tan bien funcionan estos modelos es generando
frases según las probabilidades que estimamos.</p>
<div id="ejemplo-unigramas" class="section level4 unnumbered">
<h4>Ejemplo: unigramas</h4>
<p>Generamos algunas frases bajo el modelo de unigramas. Podemos construir
una frase comenzando con el token <span class="math inline">\(&lt;s&gt;\)</span>, y paramos cuando encontramos
<span class="math inline">\(&lt;/s&gt;\)</span>. Cada token se escoge al azar según las probablidades <span class="math inline">\(P(w)\)</span>.</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-1" aria-hidden="true" tabindex="-1"></a>calc_siguiente_uni <span class="ot">&lt;-</span> <span class="cf">function</span>(texto, n_gramas){</span>
<span id="cb814-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-2" aria-hidden="true" tabindex="-1"></a>  u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb814-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-3" aria-hidden="true" tabindex="-1"></a>  unigramas_s <span class="ot">&lt;-</span> <span class="fu">arrange</span>(n_gramas[[<span class="dv">1</span>]], log_p) </span>
<span id="cb814-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-4" aria-hidden="true" tabindex="-1"></a>  prob_acum <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(<span class="fu">exp</span>(unigramas_s<span class="sc">$</span>log_p))</span>
<span id="cb814-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-5" aria-hidden="true" tabindex="-1"></a>  palabra_no <span class="ot">&lt;-</span> <span class="fu">match</span>(<span class="cn">TRUE</span>, u <span class="sc">&lt;</span> prob_acum)</span>
<span id="cb814-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.character</span>(unigramas_s[palabra_no, <span class="st">&quot;w_n_0&quot;</span>])</span>
<span id="cb814-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb814-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-8" aria-hidden="true" tabindex="-1"></a>texto <span class="ot">&lt;-</span> <span class="st">&quot;&quot;</span></span>
<span id="cb814-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-9" aria-hidden="true" tabindex="-1"></a>fin <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb814-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1215</span>)</span>
<span id="cb814-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-11" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(<span class="sc">!</span>fin){</span>
<span id="cb814-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-12" aria-hidden="true" tabindex="-1"></a>  siguiente <span class="ot">&lt;-</span> <span class="fu">calc_siguiente_uni</span>(texto, n_gramas)</span>
<span id="cb814-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-13" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">c</span>(texto, siguiente)</span>
<span id="cb814-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(siguiente <span class="sc">==</span> <span class="st">&quot;_ss_&quot;</span>){</span>
<span id="cb814-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-15" aria-hidden="true" tabindex="-1"></a>    fin <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span>
<span id="cb814-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb814-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb814-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb814-18" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(texto, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot; las que baleares del con del agua en señalándoles si de en ha mismas _punto_ se pp el de _coma_ los del que _punto_ la en reiterado _punto_ cuentan y los _coma_ derechos hoy la _coma_ al talento en buena gobierno sólo de genero aguas uvi a arreos un en en 3 dos de que es del porque que _ss_&quot;</code></pre>
</div>
<div id="ejemplo-bigramas" class="section level4" number="9.6.1.1">
<h4><span class="header-section-number">9.6.1.1</span> Ejemplo: bigramas</h4>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb816-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-1" aria-hidden="true" tabindex="-1"></a>calc_siguiente_bi <span class="ot">&lt;-</span> <span class="cf">function</span>(texto, n_gramas){</span>
<span id="cb816-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-2" aria-hidden="true" tabindex="-1"></a>  u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb816-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(texto)</span>
<span id="cb816-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-4" aria-hidden="true" tabindex="-1"></a>  anterior <span class="ot">&lt;-</span> texto[n]</span>
<span id="cb816-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-5" aria-hidden="true" tabindex="-1"></a>  siguiente_df <span class="ot">&lt;-</span> <span class="fu">filter</span>(n_gramas[[<span class="dv">2</span>]], w_n_1 <span class="sc">==</span> anterior) <span class="sc">|&gt;</span> </span>
<span id="cb816-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(log_p) </span>
<span id="cb816-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-7" aria-hidden="true" tabindex="-1"></a>  palabra_no <span class="ot">&lt;-</span> <span class="fu">match</span>(<span class="cn">TRUE</span>, u <span class="sc">&lt;</span> <span class="fu">cumsum</span>(<span class="fu">exp</span>(siguiente_df<span class="sc">$</span>log_p)))</span>
<span id="cb816-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.character</span>(siguiente_df[palabra_no, <span class="st">&quot;w_n_0&quot;</span>])</span>
<span id="cb816-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb816-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-10" aria-hidden="true" tabindex="-1"></a>texto <span class="ot">&lt;-</span> <span class="st">&quot;_s_&quot;</span></span>
<span id="cb816-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-11" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4123</span>)</span>
<span id="cb816-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-12" aria-hidden="true" tabindex="-1"></a>fin <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb816-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-13" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(<span class="sc">!</span>fin){</span>
<span id="cb816-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-14" aria-hidden="true" tabindex="-1"></a>  siguiente <span class="ot">&lt;-</span> <span class="fu">calc_siguiente_bi</span>(texto, n_gramas)</span>
<span id="cb816-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-15" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">c</span>(texto, siguiente)</span>
<span id="cb816-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(siguiente <span class="sc">==</span> <span class="st">&quot;_ss_&quot;</span>){</span>
<span id="cb816-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-17" aria-hidden="true" tabindex="-1"></a>    fin <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span>
<span id="cb816-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb816-19"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb816-20"><a href="modelos-de-lenguaje-y-n-gramas.html#cb816-20" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(texto, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;_s_ el concierto pueden encontrarse las poblaciones como la mano derecha de la delincuencia y la mañana en la trama de las alarmas en valladolid _coma_ o alemania podría haber aprendido del documento especifique los portavoces que en el 78 de mehr solar construirá tres fronteras y lo que garantiza la fundación personas indicadas todas las encuestadas 11 españoles _punto_ danays llegaba la posibilidad de la lleva puesto sus aliados parlamentarios para otro tipo de la ola que una hermana con su aventura _punto_ un feto de españa en el sip entre operadores turísticos cuya desembocadura _punto_ definitivamente del ipc previsto entregar al final _coma_ la realidad _punto_ el proceso de interposición de algeciras _coma_ el acuerdo con su educación _coma_ porque prevalecen y no han concluido y llegar al trabajo bien _punto_ _ss_&quot;</code></pre>
</div>
<div id="ejemplo-trigramas" class="section level4" number="9.6.1.2">
<h4><span class="header-section-number">9.6.1.2</span> Ejemplo: trigramas</h4>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-1" aria-hidden="true" tabindex="-1"></a>calc_siguiente_tri <span class="ot">&lt;-</span> <span class="cf">function</span>(texto, n_gramas){</span>
<span id="cb818-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-2" aria-hidden="true" tabindex="-1"></a>  u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb818-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(texto)</span>
<span id="cb818-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-4" aria-hidden="true" tabindex="-1"></a>  contexto <span class="ot">&lt;-</span> texto[<span class="fu">c</span>(n,n<span class="dv">-1</span>)]</span>
<span id="cb818-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-5" aria-hidden="true" tabindex="-1"></a>  siguiente_df <span class="ot">&lt;-</span> <span class="fu">filter</span>(n_gramas[[<span class="dv">3</span>]], w_n_1 <span class="sc">==</span> contexto[<span class="dv">1</span>], w_n_2 <span class="sc">==</span> contexto[<span class="dv">2</span>]) <span class="sc">|&gt;</span> </span>
<span id="cb818-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(log_p)</span>
<span id="cb818-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-7" aria-hidden="true" tabindex="-1"></a>  palabra_no <span class="ot">&lt;-</span> <span class="fu">match</span>(<span class="cn">TRUE</span>, u <span class="sc">&lt;</span> <span class="fu">cumsum</span>(<span class="fu">exp</span>(siguiente_df<span class="sc">$</span>log_p)))</span>
<span id="cb818-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.character</span>(siguiente_df[palabra_no, <span class="st">&quot;w_n_0&quot;</span>])</span>
<span id="cb818-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb818-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-10" aria-hidden="true" tabindex="-1"></a>texto <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;_s_&quot;</span>,<span class="st">&quot;_s_&quot;</span>)</span>
<span id="cb818-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-11" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4122</span>)</span>
<span id="cb818-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-12" aria-hidden="true" tabindex="-1"></a>fin <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb818-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-13" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(<span class="sc">!</span>fin){</span>
<span id="cb818-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-14" aria-hidden="true" tabindex="-1"></a>  siguiente <span class="ot">&lt;-</span> <span class="fu">calc_siguiente_tri</span>(texto, n_gramas)</span>
<span id="cb818-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-15" aria-hidden="true" tabindex="-1"></a>  texto <span class="ot">&lt;-</span> <span class="fu">c</span>(texto, siguiente)</span>
<span id="cb818-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(siguiente <span class="sc">==</span> <span class="st">&quot;_ss_&quot;</span>){</span>
<span id="cb818-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-17" aria-hidden="true" tabindex="-1"></a>    fin <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span>
<span id="cb818-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb818-19"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb818-20"><a href="modelos-de-lenguaje-y-n-gramas.html#cb818-20" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(texto, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;_s_ _s_ en relación con su marido figura entre los años a la formación de salida _coma_ despistado por el gran número de asuntos exteriores y economía y hacienda de los siglos xvi y xvii relacionados con la que se descarta y en el paseo de la escuela de comunicación _coma_ o su boda en normandía _punto_ al mismo tiempo _coma_ esquivar el golpe le desplazó casi 60 millones de euros para emprender estas obras supusieron la eliminación de barreras arquitectónicas _punto_ _ss_&quot;</code></pre>
<p><strong>Observación</strong>: en este ejemplo vemos cómo los textos parecen más textos reales
cuando usamos n-gramas más largos.</p>
</div>
</div>
<div id="evaluación-de-modelos-perplejidad" class="section level3" number="9.6.2">
<h3><span class="header-section-number">9.6.2</span> Evaluación de modelos: perplejidad</h3>
<p>En general,
la mejor manera de hacer la evaluación de un modelo de lenguaje es en el contexto
de su aplicación (es decir, el desempeño en la tarea final para el que construimos
nuestro modelo): por ejemplo, si se trata de corrección de ortografía, qué tanto da la palabra
correcta, o qué tanto seleccionan usuarios palabras del corrector.</p>
<p>Sin embargo también podemos hacer una evaluación intrínseca del modelo considerando
muestras de entrenamiento y prueba. Una medida usual en este contexto
es la <strong>perplejidad</strong>.</p>

<div class="resumen">
Sea <span class="math inline">\(P(W)\)</span> un modelo del lenguaje. Supongamos que observamos
un texto <span class="math inline">\(W=w_1 w_2\cdots w_N\)</span> (una cadena larga, que puede incluír varios separadores
<span class="math inline">\(&lt;/s&gt;, &lt;s&gt;\)</span>). La <strong>log-perplejidad</strong> del modelo sobre este texto es igual a
<span class="math display">\[LP(W) = -\frac{1}{N} \log P(w_1 w_2 \cdots w_N),\]</span>
que también puede escribirse como
<span class="math display">\[LP(W) = -\frac{1}{N} \sum_{i=1}^N \log P(w_i|w_1 w_2 \cdots w_{i-1})\]</span>
La perplejidad es igual a
<span class="math display">\[PP(W) = e^{LP(W)},\]</span>
que es la medida más frecuentemente reportada en modelos de lenguaje.
</div>
<p><strong>Observaciones</strong>:</p>
<ul>
<li>La log perplejidad es similar a la devianza (negativo de log-verosimilitud)
de los datos (palabras) observadas <span class="math inline">\(W\)</span> bajo el modelo <span class="math inline">\(P\)</span>.</li>
<li>Cuanto más grande es <span class="math inline">\(P(W)\)</span> bajo el modelo, menor es la perplejidad.</li>
<li>Mejores modelos tienen valores más bajos de perplejidad. Buscamos
modelos que asignen muy baja probabilidad a frases que no son
gramáticas, o no tienen sentido, y alta probabilidad a frases
que ocurren con frecuencia.</li>
</ul>
<p>Bajo el modelo de bigramas, por ejemplo, tenemos que</p>
<p><span class="math display">\[LP(W) = -\frac{1}{N} \sum_{i=1}^N \log P(w_i|w_{i-1})\]</span></p>
<p>Y para el modelo de trigramas:
<span class="math display">\[LP(W) = -\frac{1}{N} \sum_{i=1}^N \log P(w_i|w_{i-2}w_{i-1})\]</span></p>

<div class="resumen">
<ul>
<li>La evaluación de modelos la hacemos calculando la perplejidad en una
muestra de textos de prueba, que no fueron utilizados para
entrenar los modelos.</li>
<li>Para palabras no vistas, entrenamos nuestros modelos sustituyendo
palabras no frecuentes con <span class="math inline">\(&lt;unk&gt;\)</span>, y a las palabras no vistas
les asignamos el token <span class="math inline">\(&lt;unk&gt;\)</span>.
</div></li>
</ul>
<hr />
<div id="ejemplo-30" class="section level4 unnumbered">
<h4>Ejemplo</h4>
<p>Podemos usar nuestra función anterior para calcular la perplejidad. Para
los datos de entrenamiento vemos que la perplejidad de entrenamiento es mejor para
los modelos más complejos:</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb820-1" aria-hidden="true" tabindex="-1"></a>periodico_entrena <span class="ot">&lt;-</span> periodico[muestra_ind]</span>
<span id="cb820-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb820-2" aria-hidden="true" tabindex="-1"></a>textos <span class="ot">&lt;-</span> periodico_entrena[<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>]</span>
<span id="cb820-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb820-3" aria-hidden="true" tabindex="-1"></a>texto_entrena <span class="ot">&lt;-</span> <span class="fu">paste</span>(textos, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span>
<span id="cb820-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb820-4" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_entrena, n_gramas_u, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 1054.776</code></pre>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb822-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_entrena, n_gramas_u, <span class="at">n =</span> <span class="dv">2</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 174.3516</code></pre>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb824-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_entrena, n_gramas_u, <span class="at">n =</span> <span class="dv">3</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 105.3819</code></pre>
<p>Pero para la muestra de prueba:</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb826-1" aria-hidden="true" tabindex="-1"></a>periodico_prueba <span class="ot">&lt;-</span> periodico[<span class="sc">-</span>muestra_ind]</span>
<span id="cb826-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb826-2" aria-hidden="true" tabindex="-1"></a>textos <span class="ot">&lt;-</span> periodico_prueba[<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>]</span>
<span id="cb826-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb826-3" aria-hidden="true" tabindex="-1"></a>texto_prueba <span class="ot">&lt;-</span> <span class="fu">paste</span>(textos, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span>
<span id="cb826-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb826-4" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_prueba, n_gramas_u, <span class="at">n =</span> <span class="dv">1</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 1006.145</code></pre>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb828-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_prueba, n_gramas_u, <span class="at">n =</span> <span class="dv">2</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 320.2612</code></pre>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb830-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">log_prob</span>(texto_prueba, n_gramas_u, <span class="at">n =</span> <span class="dv">3</span>, <span class="at">laplace =</span> T))</span></code></pre></div>
<pre><code>##        1 
## 1554.325</code></pre>
<p>Y vemos para este ejemplo que el mejor desempeño está dado por el modelo de bigramas, aunque no hemos hecho ningún ajuste ad-hoc del parámetro <span class="math inline">\(\delta\)</span>. Como explicamos arriba,
es preferible usar otros algoritmos de suavizamiento.</p>
</div>
<div id="ejercicio-14" class="section level4 unnumbered">
<h4>Ejercicio</h4>
<p>Discute por qué:</p>
<ul>
<li>El modelo de bigramas se desempeña mejor que el de unigramas
en la muestra de prueba.</li>
<li>Parece que el modelo de trigramas, con
nuestra colección de textos chicos, parece “sobreajustar,” y tener
mal desempeño sobre la muestra de prueba.</li>
</ul>
</div>
</div>
</div>
<div id="suavizamiento-de-conteos-otros-métodos" class="section level2" number="9.7">
<h2><span class="header-section-number">9.7</span> Suavizamiento de conteos: otros métodos</h2>
<p>Como discutimos arriba, el primer problema para generalizar
a frases o textos que no hemos visto, es que muchas veces no
observamos en nuestros datos de entrenamiento
ciertos n-gramas con probabiliidad relativamente alta. Arriba
propusimos el suavizamiento de Laplace, que es una manera
burda de evitar los ceros y se basa en la idea de quitar
un poco de probabilidad a los n-gramas observados y redistribuir
sobre los no observados.</p>
<p>Podemos considerar métodos mejores observando que cuando
el contexto es muy grande (por ejemplo, trigramas), es fácil
no encontrar 0’s en frases usuales del lenguaje (por ejemplo,
encontramos “Una geometría euclideana,” “Una geometría no-euclideana,”
pero nunca observamos Una geometría hiperbólica”). En este
caso, podríamos bajar a usar los <em>bigramas</em>, y considerar solamente
el bigrama “geometría hiperbólica,” que quizá tiene algunas
ocurrencias en la muestra de entrenamiento. A este proceso se
le llama <strong>backoff</strong>.</p>
<p>Un método popular con mejor desempeño que Laplace es
el método de descuento absoluto (da) de <strong>Kneser-Ney</strong>. Consideremos el caso de bigramas.</p>
<p>En primer lugar, este método utiliza interpolación entre bigramas y unigramas,
considerando que debemos quitar algo de masa de probabilidad
a bigramas observados para distribuir en bigramas no observados. El descuento lo
hacemos absoluto (por ejemplo restando <span class="math inline">\(d=0.75\)</span>, ver <span class="citation">(<a href="#ref-jurafsky" role="doc-biblioref">Jurafsky and Martin 2000</a>)</span>)</p>
<p><span class="math display">\[P_{da}(w|a) = \frac{N(aw) - d}{N(a)} + \lambda(a) P(w).\]</span></p>
<p>Así que reducimos los conteos observados por una fracción
<span class="math inline">\(d\)</span>, e interpolamos con las probabilidad de ocurrencia de unigramas. <span class="math inline">\(\lambda(a)\)</span> es tal que la suma de todas las probabilidades es igual a 1: <span class="math inline">\(\sum_w P(w|a) = 1\)</span>. El lado derecho de esta ecuación toma valores positivos
siempre y cuando <span class="math inline">\(N(w)\geq 1\)</span>, que suponemos (vocabulario completo, quizá incluyendo unk).</p>
<p>Esta primera parte de descuento absoluto pone masa de probabilidad sobre bigramas no vistos. Podemos
mejorar si en lugar de considerar <span class="math inline">\(P(w)\)</span> consideramos una cantidad más específica, como sigue:</p>
<p>En vez de usar las probabilidades crudas
de unigramas <span class="math inline">\(P(w)\)</span>, usamos las probabilidades de continuación
de unigramas <span class="math inline">\(P_{cont}(w)\)</span>, pues aquí <span class="math inline">\(w\)</span> aparece como continuación después de <span class="math inline">\(a\)</span>:</p>
<p><span class="math display">\[P_{cont}(w) = \frac{\sum_{z\in V} I(N(zw) &gt;0) }
{ \sum_{z, b\in V} I(N(zb &gt; 0))}.\]</span></p>
<p>Que simplemente es la probabilidad de que <span class="math inline">\(w\)</span> sea una continuación después de alguna palabra (en el denominador están todas las posibles continuaciones sobre todas las palabras). Verifica que <span class="math inline">\(\sum_{w\in V} P_{cont} (w) = 1\)</span>, de forma que es una distribución de probabilidad
sobre los unigramas.</p>
<p>La idea de este método se basa en la siguiente observación:</p>
<ul>
<li>Hay palabras como <em>embargo</em> que principalmente ocurren como continuación
de palabras específicas (<strong>sin embargo</strong>). En general, su probabilidad de continuación es baja.</li>
<li>Pero <em>embargo</em> puede tener probabilidad de unigrama alto porque <em>sin embargo</em> ocurre frecuentemente.</li>
<li>En una frase como “Este es un día …,” quizá <em>aburrido</em> ocurre menos que <em>embargo</em>, pero <em>aburrido</em> es una continuación más apropiada, pues ocurre más como continuación de otras palabras.</li>
<li>Si usamos las probabilidad de continuación, veríamos que
<span class="math inline">\(P_{cont}(embargo)\)</span> es baja, pero <span class="math inline">\(P_{cont}(aburrido)\)</span> es más alta,
pues <em>aburrido</em> ocurre más como continuación.</li>
</ul>
<p>Usaríamos entonces:</p>
<p><span class="math display">\[P_{da}(w|a) = \frac{N(aw) - d}{N(a)} + \lambda(a) P_{cont}(w).\]</span></p>
<div id="desempeño" class="section level3 unnumbered">
<h3>Desempeño</h3>
<p>Cuando construimos modelos grandes, una búsqueda directa en
una base de datos usual de n-gramas puede ser lenta (por ejemplo,
considera cómo funcionaría el <em>auto-complete</em> o la corrección de ortografía).</p>
<p>Hay varias alternativas. Se pueden filtrar los n-gramas menos frecuentes (usando las ideas de arriba para hacer backoff o interpolación con unigramas), y utilizar estructuras
apropiadas para encontrar los n-gramas. Otra solución es utilizar algoritmos más simples como
<strong>stupid backoff</strong> (que se usa para colecciones muy grandes de texto),
que consiste en usar la probabilidad del (n-1)-grama multiplicado
por una constante fija <span class="math inline">\(\lambda\)</span> si no encontramos el n-grama
que buscamos (Ver <span class="citation">(<a href="#ref-jurafsky" role="doc-biblioref">Jurafsky and Martin 2000</a>)</span>).</p>
<p>Finalmente, una opción es utilizar <strong>filtros de bloom</strong> para
obtener aproximaciones de los conteos. Si la frecuencia
de un n-grama <span class="math inline">\(w\)</span> es <span class="math inline">\(f\)</span>, por ejemplo, insertamos en
el filtro el elemento <span class="math inline">\((w, 2^j)\)</span> para toda <span class="math inline">\(j\)</span> tal que
<span class="math inline">\(2^j &lt; f\)</span>. Para estimar un conteo de un n-grama observado,
simplemente checamos sucesivamente si el elemento <span class="math inline">\((w, 2^j)\)</span> está
en el filtro o no, hasta que encontramos una <span class="math inline">\(k\)</span> tal que
<span class="math inline">\((w, 2^{k+1})\)</span> no está en el filtro. Nuestra estimación
de la frecuencia del n-grama <span class="math inline">\(w\)</span> es entonces <span class="math inline">\(2^k \leq f &lt; 2^{k+1}\)</span></p>
</div>
</div>
<div id="ejemplo-corrector-de-ortografía" class="section level2" number="9.8">
<h2><span class="header-section-number">9.8</span> Ejemplo: Corrector de ortografía</h2>
<p>Como ejemplo del canal ruidoso y el papel que juega los modelos del lenguaje, podemos
ver un sistema simple de corrección de ortografía.</p>
<p>En nuestro caso, usaremos como <span class="math inline">\(P(W)\)</span> el modelo de bigramas, y el modelo de ruido
<span class="math inline">\(P(X|W)\)</span> es simple: lo construimos a partir de palabras <span class="math inline">\(p(x|w)\)</span>, y consideramos que dada
una palabra <span class="math inline">\(w\)</span>, es posible observar <span class="math inline">\(x\)</span>, donde <span class="math inline">\(w\)</span> se produce como transformación de <span class="math inline">\(x\)</span> aplicando:</p>
<ol style="list-style-type: decimal">
<li>Una eliminación de un caracter</li>
<li>Inserción de un caracter</li>
<li>Sustitución de un caracter</li>
<li>Transposición de dos caracteres adyacentes</li>
</ol>
<p>Daremos igual probabilidad a todas estas posiblidades, aunque en la realidad este modelo
debería ser más refinado (¿cómo mejorarías este modelo?¿Con qué datos?).</p>
<p>En el siguiente paso tendríamos que producir sugerencias de corrección.
En caso de encontrar una palabra que no está en el diccionario,
podemos producir palabras similares (a cierta distancia de edición),
y filtrar aquellas que están en el vocabulario (ver <a href="http://norvig.com/spell-correct.html">How to write a spelling corrector</a>).</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-1" aria-hidden="true" tabindex="-1"></a>generar_candidatos <span class="ot">&lt;-</span> <span class="cf">function</span>(palabra){</span>
<span id="cb832-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-2" aria-hidden="true" tabindex="-1"></a>  caracteres <span class="ot">&lt;-</span> <span class="fu">c</span>(letters, <span class="st">&#39;á&#39;</span>, <span class="st">&#39;é&#39;</span>, <span class="st">&#39;í&#39;</span>, <span class="st">&#39;ó&#39;</span>, <span class="st">&#39;ú&#39;</span>, <span class="st">&#39;ñ&#39;</span>)</span>
<span id="cb832-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-3" aria-hidden="true" tabindex="-1"></a>  pares <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">0</span><span class="sc">:</span>(<span class="fu">nchar</span>(palabra)), <span class="cf">function</span>(i){</span>
<span id="cb832-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="fu">str_sub</span>(palabra, <span class="dv">1</span>, i), <span class="fu">str_sub</span>(palabra, i<span class="sc">+</span><span class="dv">1</span>, <span class="fu">nchar</span>(palabra)))</span>
<span id="cb832-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-5" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb832-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-6" aria-hidden="true" tabindex="-1"></a>  eliminaciones <span class="ot">&lt;-</span> pares <span class="sc">|&gt;</span> <span class="fu">map</span>(<span class="cf">function</span>(x){ <span class="fu">paste0</span>(x[<span class="dv">1</span>], <span class="fu">str_sub</span>(x[<span class="dv">2</span>],<span class="dv">2</span>,<span class="sc">-</span><span class="dv">1</span>))})</span>
<span id="cb832-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-7" aria-hidden="true" tabindex="-1"></a>  sustituciones <span class="ot">&lt;-</span> pares <span class="sc">|&gt;</span> <span class="fu">map</span>(<span class="cf">function</span>(x)</span>
<span id="cb832-8"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">map</span>(caracteres, <span class="cf">function</span>(car){</span>
<span id="cb832-9"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">paste0</span>(x[<span class="dv">1</span>], car, <span class="fu">str_sub</span>(x[<span class="dv">2</span>], <span class="dv">2</span> ,<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb832-10"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-10" aria-hidden="true" tabindex="-1"></a>  })) <span class="sc">|&gt;</span> <span class="fu">flatten</span>() </span>
<span id="cb832-11"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-11" aria-hidden="true" tabindex="-1"></a>  inserciones <span class="ot">&lt;-</span> pares <span class="sc">|&gt;</span> <span class="fu">map</span>(<span class="cf">function</span>(x){</span>
<span id="cb832-12"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">map</span>(caracteres, <span class="cf">function</span>(car) <span class="fu">paste0</span>(x[<span class="dv">1</span>], car, x[<span class="dv">2</span>]))</span>
<span id="cb832-13"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-13" aria-hidden="true" tabindex="-1"></a>  }) <span class="sc">|&gt;</span> <span class="fu">flatten</span>()</span>
<span id="cb832-14"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-14" aria-hidden="true" tabindex="-1"></a>  transposiciones <span class="ot">&lt;-</span> pares <span class="sc">|&gt;</span> <span class="fu">map</span>(<span class="cf">function</span>(x){</span>
<span id="cb832-15"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">paste0</span>(x[<span class="dv">1</span>], <span class="fu">str_sub</span>(x[<span class="dv">2</span>],<span class="dv">2</span>,<span class="dv">2</span>), <span class="fu">str_sub</span>(x[<span class="dv">2</span>],<span class="dv">1</span>,<span class="dv">1</span>), <span class="fu">str_sub</span>(x[<span class="dv">2</span>],<span class="dv">3</span>,<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb832-16"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-16" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb832-17"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(eliminaciones, sustituciones, transposiciones, inserciones)</span>
<span id="cb832-18"><a href="modelos-de-lenguaje-y-n-gramas.html#cb832-18" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb833-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb833-1" aria-hidden="true" tabindex="-1"></a>candidatos <span class="ot">&lt;-</span> <span class="fu">generar_candidatos</span>(<span class="st">&quot;solado&quot;</span>)</span>
<span id="cb833-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb833-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sprintf</span>(<span class="st">&quot;Número de candidatos generados: %0.i&quot;</span>, <span class="fu">length</span>(candidatos))</span></code></pre></div>
<pre><code>## [1] &quot;Número de candidatos generados: 462&quot;</code></pre>
<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb835-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb835-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Algunos candidatos:&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Algunos candidatos:&quot;</code></pre>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb837-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb837-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(candidatos)</span></code></pre></div>
<pre><code>## [[1]]
## [1] &quot;olado&quot;
## 
## [[2]]
## [1] &quot;slado&quot;
## 
## [[3]]
## [1] &quot;soado&quot;
## 
## [[4]]
## [1] &quot;soldo&quot;
## 
## [[5]]
## [1] &quot;solao&quot;
## 
## [[6]]
## [1] &quot;solad&quot;</code></pre>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-1" aria-hidden="true" tabindex="-1"></a>sugerir <span class="ot">&lt;-</span> <span class="cf">function</span>(frase, mod_bi){</span>
<span id="cb839-2"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-2" aria-hidden="true" tabindex="-1"></a>  tokens <span class="ot">&lt;-</span> <span class="fu">normalizar</span>(frase) <span class="sc">|&gt;</span> <span class="fu">str_split</span>(<span class="st">&quot; &quot;</span>) <span class="sc">|&gt;</span> <span class="fu">first</span>() <span class="sc">|&gt;</span> <span class="fu">tail</span>(<span class="dv">2</span>)</span>
<span id="cb839-3"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-3" aria-hidden="true" tabindex="-1"></a>  candidatos <span class="ot">&lt;-</span> <span class="fu">generar_candidatos</span>(tokens[<span class="dv">2</span>])</span>
<span id="cb839-4"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-4" aria-hidden="true" tabindex="-1"></a>  candidatos_tbl <span class="ot">&lt;-</span> mod_bi <span class="sc">|&gt;</span> <span class="fu">filter</span>(w_n_1 <span class="sc">==</span> tokens[<span class="dv">1</span>], w_n_0 <span class="sc">%in%</span> <span class="fu">c</span>(tokens[<span class="dv">2</span>], candidatos)) <span class="sc">|&gt;</span> </span>
<span id="cb839-5"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">log_posterior =</span> <span class="dv">0</span> <span class="sc">+</span> log_p) <span class="co"># suponemos todos las corrupciones igualmente probabiles</span></span>
<span id="cb839-6"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(candidatos_tbl, <span class="fu">desc</span>(log_posterior))</span>
<span id="cb839-7"><a href="modelos-de-lenguaje-y-n-gramas.html#cb839-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb840-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb840-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sugerir</span>(<span class="fu">c</span>(<span class="st">&quot;esto es un echo&quot;</span>), mod_bi) <span class="sc">|&gt;</span> <span class="fu">head</span>()</span></code></pre></div>
<pre><code>## # A tibble: 5 × 6
##   w_n_1 w_n_0   num denom  log_p log_posterior
##   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;
## 1 un    hecho   115 66008  -6.35         -6.35
## 2 un    techo    20 66008  -8.10         -8.10
## 3 un    eco       4 66008  -9.71         -9.71
## 4 un    ocho      4 66008  -9.71         -9.71
## 5 un    pecho     1 66008 -11.1         -11.1</code></pre>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb842-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb842-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sugerir</span>(<span class="st">&quot;dice que lo hechó&quot;</span>, mod_bi)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 6
##   w_n_1 w_n_0   num denom log_p log_posterior
##   &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;         &lt;dbl&gt;
## 1 lo    hecho    13 26883 -7.63         -7.63
## 2 lo    echó      5 26883 -8.59         -8.59</code></pre>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="modelos-de-lenguaje-y-n-gramas.html#cb844-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sugerir</span>(<span class="st">&quot;un pantalón asul&quot;</span>, mod_bi)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 6
##   w_n_1    w_n_0   num denom log_p log_posterior
##   &lt;chr&gt;    &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;         &lt;dbl&gt;
## 1 pantalón azul      2    48 -3.18         -3.18</code></pre>
<p>Este modelo está basado en bigramas, pero podemos usar también unigramas por ejemplo para
producir recomendaciones cuando no encontremos bigramas apropiados.</p>

</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-jurafsky" class="csl-entry">
Jurafsky, Daniel, and James H. Martin. 2000. <em>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition</em>. 1st ed. Upper Saddle River, NJ, USA: Prentice Hall PTR.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="detección-de-comunidades.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="representación-de-palabras-y-word2vec.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/felipegonzalez/metodos-analiticos-mcd-2022/edit/master/notas/08-modelos-lenguaje.Rmd",
"text": "Editar"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
